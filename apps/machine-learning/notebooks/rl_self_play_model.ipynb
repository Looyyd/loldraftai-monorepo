{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from IPython.display import display, Image as IPImage\n",
    "import os\n",
    "from typing import List, Optional\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "from utils import DATA_DIR\n",
    "from utils.rl.env import FlexibleRoleDraftEnv, action_mask_fn\n",
    "from utils.rl.self_play import ModelPool, SelfPlayWithPoolWrapper\n",
    "from utils.rl.visualizer import integrate_with_env\n",
    "from utils.match_prediction import get_best_device, PREPARED_DATA_DIR\n",
    "\n",
    "import warnings\n",
    "\n",
    "# sb3_contrib is not updated to latest api, this is the message we are ignoring:\n",
    "# WARN: env.get_action_mask to get variables from other wrappers is deprecated and will be removed in v1.0\n",
    "warnings.filterwarnings(\"ignore\", message=\".*env.get_action_mask.*\")\n",
    "\n",
    "device = get_best_device()\n",
    "\n",
    "\n",
    "# Create a simplified model pool for visualization\n",
    "class VisualizationModelPool(ModelPool):\n",
    "    def __init__(self, model_path: str):\n",
    "        super().__init__(save_dir=\"\")  # We don't need save_dir for visualization\n",
    "        self.model = MaskablePPO.load(\n",
    "            model_path, device=device\n",
    "        )  # need to specify device to avoid error because of numeric constraint\n",
    "        # TODO: this might cause problems if inference is done on a different device\n",
    "\n",
    "    def sample_opponent(self):\n",
    "        \"\"\"Always return the same model for visualization\"\"\"\n",
    "        return self.model\n",
    "\n",
    "\n",
    "# TODO: refactor to commong code\n",
    "def get_latest_patches(n_patches: int = 5) -> List[int]:\n",
    "    \"\"\"\n",
    "    Load patch mapping and return the n latest numerical patches.\n",
    "\n",
    "    Args:\n",
    "        n_patches: Number of latest patches to return\n",
    "\n",
    "    Returns:\n",
    "        List of numerical patch values, sorted from newest to oldest\n",
    "    \"\"\"\n",
    "    patch_mapping_path = Path(PREPARED_DATA_DIR) / \"patch_mapping.pkl\"\n",
    "    with open(patch_mapping_path, \"rb\") as f:\n",
    "        patch_data = pickle.load(f)\n",
    "\n",
    "    # Get unique raw patch numbers\n",
    "    raw_patches = sorted(set(patch_data[\"mapping\"].keys()))\n",
    "\n",
    "    # Return the n latest patches (highest numbers)\n",
    "    return raw_patches[-n_patches:]\n",
    "\n",
    "\n",
    "patches = get_latest_patches()\n",
    "\n",
    "\n",
    "def visualize_self_play(\n",
    "    model_path: str = f\"{DATA_DIR}/self_play_models/final_model\",\n",
    "    num_games: int = 1,\n",
    "    team1_custom_role_matrix: Optional[np.ndarray] = None,\n",
    "    team2_custom_role_matrix: Optional[np.ndarray] = None,\n",
    "    team1_use_fallback: bool = False,\n",
    "    team2_use_fallback: bool = False,\n",
    "    numeric_patch: Optional[int] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize self-play matches between two teams, optionally with custom role matrices.\n",
    "    Plays num_games matches with team1 as blue and team2 as red, then num_games matches with sides swapped.\n",
    "\n",
    "    Parameters:\n",
    "        model_path: Path to the trained model.\n",
    "        num_games: Number of games to play per side.\n",
    "        team1_custom_role_matrix: Optional custom role matrix for team1.\n",
    "        team2_custom_role_matrix: Optional custom role matrix for team2.\n",
    "        team1_use_fallback: If True, use fallback role matrix for team1.\n",
    "        team2_use_fallback: If True, use fallback role matrix for team2.\n",
    "        numeric_patch: Optional patch number to use.\n",
    "    \"\"\"\n",
    "    # Load the model and create the pool\n",
    "    model_pool = VisualizationModelPool(model_path)\n",
    "\n",
    "    side_configurations = [\n",
    "        # First num_games games, team1 as blue, team2 as red\n",
    "        {\n",
    "            \"agent_side\": \"blue\",\n",
    "            \"blue_custom_role_matrix\": team1_custom_role_matrix,\n",
    "            \"blue_use_fallback\": team1_use_fallback,\n",
    "            \"red_custom_role_matrix\": team2_custom_role_matrix,\n",
    "            \"red_use_fallback\": team2_use_fallback,\n",
    "            \"label\": \"Team1 as Blue, Team2 as Red\"\n",
    "        },\n",
    "        # Second num_games games, team2 as blue, team1 as red\n",
    "        {\n",
    "            \"agent_side\": \"blue\",\n",
    "            \"blue_custom_role_matrix\": team2_custom_role_matrix,\n",
    "            \"blue_use_fallback\": team2_use_fallback,\n",
    "            \"red_custom_role_matrix\": team1_custom_role_matrix,\n",
    "            \"red_use_fallback\": team1_use_fallback,\n",
    "            \"label\": \"Team2 as Blue, Team1 as Red\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for config in side_configurations:\n",
    "        print(f\"\\n{'='*50}\\n{config['label']}\\n{'='*50}\")\n",
    "        for game in range(num_games):\n",
    "            print(f\"\\nGame {game + 1}:\")\n",
    "            # Create and wrap the environment each time\n",
    "            env = integrate_with_env(FlexibleRoleDraftEnv)(patches=patches)\n",
    "\n",
    "            # TODO: first obs is without patch info! need to fix that\n",
    "            obs, _ = env.reset()\n",
    "\n",
    "            if numeric_patch is not None:\n",
    "                env.patch = numeric_patch\n",
    "\n",
    "            # Set custom role matrices\n",
    "            if config[\"blue_custom_role_matrix\"] is not None:\n",
    "                if config[\"blue_use_fallback\"]:\n",
    "                    env.state.blue_role_matrix = env.state.blue_fallback_role_matrix.copy()\n",
    "                else:\n",
    "                    env.state.blue_role_matrix = config[\"blue_custom_role_matrix\"].copy()\n",
    "            if config[\"red_custom_role_matrix\"] is not None:\n",
    "                if config[\"red_use_fallback\"]:\n",
    "                    env.state.red_role_matrix = env.state.red_fallback_role_matrix.copy()\n",
    "                else:\n",
    "                    env.state.red_role_matrix = config[\"red_custom_role_matrix\"].copy()\n",
    "\n",
    "            env = SelfPlayWithPoolWrapper(\n",
    "                env, model_pool, agent_side=config[\"agent_side\"]\n",
    "            )\n",
    "            env = ActionMasker(env, action_mask_fn)\n",
    "\n",
    "            done = False\n",
    "            truncated = False\n",
    "\n",
    "            while not done and not truncated:\n",
    "                # Get the action mask\n",
    "                action_masks = get_action_masks(env)\n",
    "                # Use the action_masks when predicting the action\n",
    "                action, _states = model_pool.model.predict(\n",
    "                    obs, action_masks=action_masks, deterministic=True\n",
    "                )\n",
    "\n",
    "                # Step the environment\n",
    "                obs, reward, done, truncated, info = env.step(int(action))\n",
    "\n",
    "            print(f\"Episode reward ({config['agent_side']} winrate):\", reward)\n",
    "            # Get the final render\n",
    "            image_data = env.render()\n",
    "            if image_data is not None:\n",
    "                display(IPImage(data=image_data))\n",
    "            else:\n",
    "                print(\"Draft is not complete or visualization is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View multiple games\n",
    "visualize_self_play(num_games=1, numeric_patch=14 * 50 + 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from IPython.display import display, Image as IPImage, clear_output\n",
    "import os\n",
    "from typing import List, Optional, Set, Dict, Tuple\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from utils import DATA_DIR\n",
    "from utils.rl.env import FlexibleRoleDraftEnv, action_mask_fn\n",
    "from utils.rl.self_play import ModelPool\n",
    "from utils.rl.visualizer import integrate_with_env\n",
    "from utils.match_prediction import get_best_device, PREPARED_DATA_DIR\n",
    "from utils.rl.champions import Champion\n",
    "from difflib import get_close_matches\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import torch as th\n",
    "\n",
    "# Suppress deprecated warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*env.get_action_mask.*\")\n",
    "\n",
    "device = get_best_device()\n",
    "\n",
    "\n",
    "def get_latest_patches(n_patches: int = 5) -> List[int]:\n",
    "    \"\"\"\n",
    "    Load patch mapping and return the n latest numerical patches.\n",
    "\n",
    "    Args:\n",
    "        n_patches: Number of latest patches to return\n",
    "\n",
    "    Returns:\n",
    "        List of numerical patch values, sorted from newest to oldest\n",
    "    \"\"\"\n",
    "    patch_mapping_path = Path(PREPARED_DATA_DIR) / \"patch_mapping.pkl\"\n",
    "    with open(patch_mapping_path, \"rb\") as f:\n",
    "        patch_data = pickle.load(f)\n",
    "\n",
    "    # Get unique raw patch numbers\n",
    "    raw_patches = sorted(set(patch_data[\"mapping\"].keys()))\n",
    "\n",
    "    # Return the n latest patches (highest numbers)\n",
    "    return raw_patches[-n_patches:]\n",
    "\n",
    "\n",
    "patches = get_latest_patches()\n",
    "\n",
    "\n",
    "# Create a simplified model pool for visualization\n",
    "class VisualizationModelPool(ModelPool):\n",
    "    def __init__(self, model_path: str):\n",
    "        super().__init__(save_dir=\"\")  # We don't need save_dir for visualization\n",
    "        self.model = MaskablePPO.load(\n",
    "            model_path, device=device\n",
    "        )  # Load the trained model\n",
    "\n",
    "    def sample_opponent(self):\n",
    "        \"\"\"Always return the same model for visualization\"\"\"\n",
    "        return self.model\n",
    "\n",
    "\n",
    "def get_action_suggestions(\n",
    "    model: MaskablePPO,\n",
    "    obs: Dict[str, np.ndarray],\n",
    "    action_mask: np.ndarray,\n",
    "    n_suggestions: int = 5,\n",
    "    picks_to_watch: Optional[List[Champion]] = None,\n",
    ") -> Tuple[List[Tuple[int, float]], List[Tuple[int, float]]]:\n",
    "    \"\"\"\n",
    "    Get top n suggested actions and probabilities for specific champions from the model.\n",
    "\n",
    "    Args:\n",
    "        model: The trained RL model\n",
    "        obs: Current observation\n",
    "        action_mask: Action mask indicating valid actions\n",
    "        n_suggestions: Number of top suggestions to return\n",
    "        picks_to_watch: Optional list of Champion objects to track probabilities for\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - List of (action_id, probability) for top n suggestions\n",
    "        - List of (action_id, probability) for watched picks that are valid moves\n",
    "    \"\"\"\n",
    "    # Handle both dictionary and tuple observations\n",
    "    if isinstance(obs, tuple):\n",
    "        obs = obs[0]\n",
    "\n",
    "    # Get action probabilities from model's policy\n",
    "    obs_tensor = {\n",
    "        k: th.from_numpy(v).unsqueeze(0).to(model.device) for k, v in obs.items()\n",
    "    }\n",
    "    with th.no_grad():\n",
    "        distribution = model.policy.get_distribution(obs_tensor)\n",
    "        action_probs = distribution.distribution.probs[0].cpu().numpy()\n",
    "\n",
    "    # Mask invalid actions\n",
    "    action_probs = action_probs * action_mask\n",
    "\n",
    "    # Normalize probabilities\n",
    "    action_probs /= action_probs.sum() + 1e-8\n",
    "\n",
    "    # Get top n valid actions\n",
    "    top_indices = np.argsort(action_probs)[-n_suggestions:][::-1]\n",
    "    top_suggestions = [(int(idx), float(action_probs[idx])) for idx in top_indices]\n",
    "\n",
    "    # Get probabilities for watched picks if they're valid moves\n",
    "    watched_suggestions = []\n",
    "    if picks_to_watch:\n",
    "        for champion in picks_to_watch:\n",
    "            if action_mask[champion.id]:  # Only include if it's a valid move\n",
    "                watched_suggestions.append(\n",
    "                    (champion.id, float(action_probs[champion.id]))\n",
    "                )\n",
    "        # Sort watched picks by probability\n",
    "        watched_suggestions.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return top_suggestions, watched_suggestions\n",
    "\n",
    "\n",
    "def create_role_matrix_from_pools(\n",
    "    champion_pools: Dict[str, List[Champion]]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a role matrix from specified champion pools.\n",
    "\n",
    "    Args:\n",
    "        champion_pools: Dictionary mapping role names to lists of Champions.\n",
    "\n",
    "    Returns:\n",
    "        Numpy array representing the role matrix.\n",
    "    \"\"\"\n",
    "    num_champions = (\n",
    "        max(champ.id for champ in Champion) + 2\n",
    "    )  # +2 I think because of unknown champions, TODO: load it\n",
    "    num_roles = 5\n",
    "    role_indices = {\"TOP\": 0, \"JUNGLE\": 1, \"MID\": 2, \"BOT\": 3, \"UTILITY\": 4}\n",
    "    role_matrix = np.zeros((num_champions, num_roles), dtype=np.int8)\n",
    "    for role_name, champions in champion_pools.items():\n",
    "        role_idx = role_indices[role_name.upper()]\n",
    "        for champ in champions:\n",
    "            role_matrix[champ.id, role_idx] = 1\n",
    "    return role_matrix\n",
    "\n",
    "\n",
    "def human_vs_human_with_suggestions(\n",
    "    model_path: str = f\"{DATA_DIR}/self_play_models/final_model\",\n",
    "    blue_custom_role_matrix: Optional[np.ndarray] = None,\n",
    "    red_custom_role_matrix: Optional[np.ndarray] = None,\n",
    "    blue_use_fallback: bool = False,\n",
    "    red_use_fallback: bool = False,\n",
    "    numeric_patch: Optional[int] = None,\n",
    "    picks_to_watch: Optional[List[Champion]] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Allow a human to select all moves from both sides, with the model suggesting moves.\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to the trained model.\n",
    "        blue_custom_role_matrix: Custom role matrix for blue team.\n",
    "        red_custom_role_matrix: Custom role matrix for red team.\n",
    "        blue_use_fallback: If True, use fallback (all champions) for blue team.\n",
    "        red_use_fallback: If True, use fallback (all champions) for red team.\n",
    "        picks_to_watch: Optional list of Champion objects to track probabilities for\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model_pool = VisualizationModelPool(model_path)\n",
    "\n",
    "    # Create and wrap the environment\n",
    "    env = integrate_with_env(FlexibleRoleDraftEnv)(patches=patches)\n",
    "    env = ActionMasker(env, action_mask_fn)\n",
    "    obs, _ = env.reset()  # reset now to create the state\n",
    "\n",
    "    if numeric_patch is not None:\n",
    "        env.patch = numeric_patch\n",
    "\n",
    "    # Override role matrices if provided\n",
    "    if blue_custom_role_matrix is not None:\n",
    "        env.state.blue_role_matrix = blue_custom_role_matrix.copy()\n",
    "    if red_custom_role_matrix is not None:\n",
    "        env.state.red_role_matrix = red_custom_role_matrix.copy()\n",
    "\n",
    "    # Use fallback matrices if specified\n",
    "    if blue_use_fallback:\n",
    "        env.state.blue_role_matrix = env.state.blue_fallback_role_matrix.copy()\n",
    "    if red_use_fallback:\n",
    "        env.state.red_role_matrix = env.state.red_fallback_role_matrix.copy()\n",
    "\n",
    "    # Create lookup dictionaries for champion names\n",
    "    id_to_name = {champion.id: champion.display_name for champion in Champion}\n",
    "    name_to_id = {champion.display_name.lower(): champion.id for champion in Champion}\n",
    "    # Add common abbreviations\n",
    "    name_to_id.update(\n",
    "        {\n",
    "            \"tf\": name_to_id[\"twisted fate\"],\n",
    "            \"mf\": name_to_id[\"miss fortune\"],\n",
    "            \"asol\": name_to_id[\"aurelion sol\"],\n",
    "            \"j4\": name_to_id[\"jarvan iv\"],\n",
    "            \"tk\": name_to_id[\"tahm kench\"],\n",
    "            # Add more abbreviations as needed\n",
    "        }\n",
    "    )\n",
    "\n",
    "    roles = [\"TOP\", \"JUNGLE\", \"MID\", \"BOT\", \"UTILITY\"]\n",
    "\n",
    "    # ANSI color codes\n",
    "    BLUE = \"\\033[94m\"\n",
    "    RED = \"\\033[91m\"\n",
    "    GREEN = \"\\033[92m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "    BAN = \"\\033[95m\"\n",
    "    PICK = \"\\033[96m\"\n",
    "\n",
    "    # Initialize variables to keep track of the draft\n",
    "    blue_bans: List[int] = []\n",
    "    red_bans: List[int] = []\n",
    "    draft_history: List[dict] = []\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action_mask = env.get_action_mask()\n",
    "        valid_actions = np.where(action_mask == 1)[0]\n",
    "        action_info = env.draft_order[env.current_step]\n",
    "        current_team = action_info[\"team\"]\n",
    "        phase = action_info[\"phase\"]\n",
    "\n",
    "        # Fetch model suggestions\n",
    "        suggestions, watched_picks = get_action_suggestions(\n",
    "            model_pool.model,\n",
    "            obs,\n",
    "            action_mask,\n",
    "            n_suggestions=5,\n",
    "            picks_to_watch=picks_to_watch,\n",
    "        )\n",
    "        suggestions = [\n",
    "            (id_to_name.get(action, \"Unknown\"), prob) for action, prob in suggestions\n",
    "        ]\n",
    "        watched_picks = [\n",
    "            (id_to_name.get(action, \"Unknown\"), prob) for action, prob in watched_picks\n",
    "        ]\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        # Display model suggestions\n",
    "        print(\"\\nModel Suggestions:\")\n",
    "        print(\"-\" * 100)\n",
    "        for name, prob in suggestions:\n",
    "            print(f\"{name:<20} - Probability: {prob:.2%}\")\n",
    "\n",
    "        # Display watched picks if any\n",
    "        if watched_picks:\n",
    "            print(\"\\nWatched Picks:\")\n",
    "            print(\"-\" * 100)\n",
    "            for name, prob in watched_picks:\n",
    "                print(f\"{name:<20} - Probability: {prob:.2%}\")\n",
    "\n",
    "        # Display current state\n",
    "        print(\n",
    "            f\"{BOLD}Draft Phase: {phase}, Team: {'BLUE' if current_team == 0 else 'RED'}{RESET}\"\n",
    "        )\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "        # Print bans\n",
    "        print(\"\\nBans:\")\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"{'Order':<10}{BLUE}BLUE{RESET:<20}{RED}RED{RESET:<20}\")\n",
    "        print(\"-\" * 50)\n",
    "        max_bans = max(len(blue_bans), len(red_bans))\n",
    "        for i in range(max_bans):\n",
    "            blue_ban = (\n",
    "                id_to_name.get(blue_bans[i], \"---\") if i < len(blue_bans) else \"---\"\n",
    "            )\n",
    "            red_ban = id_to_name.get(red_bans[i], \"---\") if i < len(red_bans) else \"---\"\n",
    "            print(f\"{BAN}Ban {i+1}{RESET:<6}{blue_ban:<20}{red_ban:<20}\")\n",
    "\n",
    "        # Print picks\n",
    "        print(\"\\nPicks:\")\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"{'Order':<10}{BLUE}BLUE{RESET:<20}{RED}RED{RESET:<20}\")\n",
    "        print(\"-\" * 50)\n",
    "        blue_picks = env.state.blue_picks\n",
    "        red_picks = env.state.red_picks\n",
    "        max_picks = max(len(blue_picks), len(red_picks))\n",
    "        for i in range(max_picks):\n",
    "            blue_pick = (\n",
    "                id_to_name.get(blue_picks[i], \"---\") if i < len(blue_picks) else \"---\"\n",
    "            )\n",
    "            red_pick = (\n",
    "                id_to_name.get(red_picks[i], \"---\") if i < len(red_picks) else \"---\"\n",
    "            )\n",
    "            print(f\"{PICK}Pick {i+1}{RESET:<6}{blue_pick:<20}{red_pick:<20}\")\n",
    "\n",
    "        # Print team compositions\n",
    "        print(\"\\nTeam Compositions:\")\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"{'Role':<10}{BLUE}BLUE{RESET:<20}{RED}RED{RESET:<20}\")\n",
    "        print(\"-\" * 50)\n",
    "        for role in roles:\n",
    "            blue_champ = \"---\"\n",
    "            red_champ = \"---\"\n",
    "            # Find the champion assigned to this role\n",
    "            for champ_id, assigned_role in env.state.blue_roles.items():\n",
    "                if assigned_role == role:\n",
    "                    blue_champ = id_to_name.get(champ_id, \"???\")\n",
    "                    break\n",
    "            for champ_id, assigned_role in env.state.red_roles.items():\n",
    "                if assigned_role == role:\n",
    "                    red_champ = id_to_name.get(champ_id, \"???\")\n",
    "                    break\n",
    "            print(f\"{role:<10}{blue_champ:<20}{red_champ:<20}\")\n",
    "\n",
    "        # Prompt for human input\n",
    "        while True:\n",
    "            try:\n",
    "                if phase == 0:\n",
    "                    prompt = \"\\nEnter champion to BAN: \"\n",
    "                elif phase == 1:\n",
    "                    prompt = \"\\nEnter champion to PICK: \"\n",
    "                elif phase == 2:\n",
    "                    # Get the role to assign\n",
    "                    role_index = action_info[\"role_index\"]\n",
    "                    current_role = roles[role_index]\n",
    "                    prompt = f\"\\nAssign champion to {current_role}: \"\n",
    "                else:\n",
    "                    prompt = \"\\nEnter action: \"\n",
    "\n",
    "                search = input(prompt)\n",
    "                if not search:\n",
    "                    print(\"Input cannot be empty. Please try again.\")\n",
    "                    continue\n",
    "\n",
    "                # Process human input to get champion ID\n",
    "                search_term = search.lower().strip()\n",
    "                chosen_id = None\n",
    "\n",
    "                # Direct match with name or abbreviation\n",
    "                if search_term in name_to_id:\n",
    "                    chosen_id = name_to_id[search_term]\n",
    "                else:\n",
    "                    # Try to find close matches\n",
    "                    all_names = list(name_to_id.keys())\n",
    "                    matches = get_close_matches(search_term, all_names, n=5, cutoff=0.6)\n",
    "                    if not matches:\n",
    "                        print(\n",
    "                            \"No champions found matching that name. Please try again.\"\n",
    "                        )\n",
    "                        continue\n",
    "                    # Show matches\n",
    "                    print(\"\\nDid you mean:\")\n",
    "                    for idx, name in enumerate(matches):\n",
    "                        print(f\"{idx + 1}. {name.title()}\")\n",
    "                    choice = input(\"Enter number (or press Enter to search again): \")\n",
    "                    if not choice:\n",
    "                        continue\n",
    "                    try:\n",
    "                        choice_idx = int(choice) - 1\n",
    "                        if choice_idx < 0 or choice_idx >= len(matches):\n",
    "                            raise IndexError\n",
    "                        chosen_id = name_to_id[matches[choice_idx]]\n",
    "                    except (ValueError, IndexError):\n",
    "                        print(\"Invalid choice. Please try again.\")\n",
    "                        continue\n",
    "\n",
    "                if chosen_id not in valid_actions:\n",
    "                    print(\n",
    "                        f\"{id_to_name.get(chosen_id, 'Unknown')} is not available. Please choose again.\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                print(\"Please try again.\")\n",
    "\n",
    "        # Keep track of bans\n",
    "        if phase == 0:\n",
    "            if current_team == 0:\n",
    "                blue_bans.append(chosen_id)\n",
    "            else:\n",
    "                red_bans.append(chosen_id)\n",
    "\n",
    "        # Store draft history\n",
    "        draft_history.append(\n",
    "            {\n",
    "                \"phase\": phase,\n",
    "                \"team\": current_team,\n",
    "                \"chosen_action\": chosen_id,\n",
    "                \"suggestions\": suggestions,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        obs, reward, done, truncated, info = env.step(chosen_id)\n",
    "\n",
    "    # After the draft is complete\n",
    "    clear_output(wait=True)\n",
    "    print(\"\\nFinal Draft:\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    # Print team compositions\n",
    "    print(\"\\nTeam Compositions:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Role':<10}{BLUE}BLUE{RESET:<20}{RED}RED{RESET:<20}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for role in roles:\n",
    "        blue_champ = \"---\"\n",
    "        red_champ = \"---\"\n",
    "        # Find the champion assigned to this role\n",
    "        for champ_id, assigned_role in env.state.blue_roles.items():\n",
    "            if assigned_role == role:\n",
    "                blue_champ = id_to_name.get(champ_id, \"???\")\n",
    "                break\n",
    "        for champ_id, assigned_role in env.state.red_roles.items():\n",
    "            if assigned_role == role:\n",
    "                red_champ = id_to_name.get(champ_id, \"???\")\n",
    "                break\n",
    "\n",
    "        print(f\"{role:<10}{blue_champ:<20}{red_champ:<20}\")\n",
    "\n",
    "    print(\"\\nDraft Complete!\")\n",
    "    print(\"Final winrate prediction (blue side winrate):\", reward)\n",
    "\n",
    "    # Get the final render\n",
    "    image_data = env.render()\n",
    "    if image_data is not None:\n",
    "        display(IPImage(data=image_data))\n",
    "    else:\n",
    "        print(\"Visualization not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Prepare custom champion pools for roles\n",
    "from utils.rl.champions import Champion\n",
    "\n",
    "guerric_jungle_pool = [\n",
    "    Champion.WARWICK,\n",
    "    Champion.HECARIM,\n",
    "    Champion.SKARNER,\n",
    "    Champion.UDYR,\n",
    "    Champion.REK_SAI,\n",
    "    Champion.GRAVES,\n",
    "]\n",
    "\n",
    "filip_utility_pool = [\n",
    "    Champion.LEONA,\n",
    "    Champion.BRAUM,\n",
    "    Champion.BARD,\n",
    "    Champion.NAMI,\n",
    "    Champion.RAKAN,\n",
    "    Champion.JANNA,\n",
    "    Champion.LULU,\n",
    "    Champion.MAOKAI,\n",
    "    Champion.BLITZCRANK,\n",
    "]\n",
    "\n",
    "# Actual players:\n",
    "filip_jungle_pool = [\n",
    "    Champion.IVERN,\n",
    "    Champion.SEJUANI,\n",
    "    Champion.ZYRA,\n",
    "    Champion.ZAC,\n",
    "    Champion.BRIAR,\n",
    "    Champion.POPPY,\n",
    "    Champion.RAMMUS,\n",
    "    Champion.AMUMU,\n",
    "    # Champion.FIDDLESTICKS,\n",
    "    # Champion.TALIYAH,\n",
    "]\n",
    "\n",
    "geoffroy_bot_pool = [\n",
    "    Champion.VEIGAR,\n",
    "    Champion.ZIGGS,\n",
    "    Champion.TRISTANA,\n",
    "    Champion.JINX,\n",
    "    Champion.VAYNE,\n",
    "    Champion.EZREAL,\n",
    "    Champion.ASHE,\n",
    "    Champion.KOG_MAW,\n",
    "    Champion.XAYAH,\n",
    "    Champion.HWEI,\n",
    "    Champion.SERAPHINE,\n",
    "    Champion.VARUS,\n",
    "    Champion.SWAIN,\n",
    "]\n",
    "\n",
    "cyprien_mid_pool = [\n",
    "    Champion.AHRI,\n",
    "    Champion.AKALI,\n",
    "    Champion.ORIANNA,\n",
    "    Champion.XERATH,\n",
    "    Champion.RYZE,\n",
    "    Champion.AZIR,\n",
    "    Champion.VIKTOR,\n",
    "    Champion.LEBLANC,\n",
    "    Champion.JAYCE,\n",
    "    Champion.YONE,\n",
    "]\n",
    "\n",
    "arthur_top_pool = [\n",
    "    Champion.K_SANTE,\n",
    "    Champion.POPPY,\n",
    "    Champion.JAX,\n",
    "    Champion.YONE,\n",
    "]\n",
    "\n",
    "mathias_utility_pool = [\n",
    "    Champion.BARD,\n",
    "    Champion.ZAC,\n",
    "    Champion.PYKE,\n",
    "    Champion.XERATH,\n",
    "    Champion.PANTHEON,\n",
    "    Champion.BRAND,\n",
    "    Champion.NEEKO,\n",
    "    Champion.SYLAS,\n",
    "    Champion.SHACO,\n",
    "    Champion.SWAIN,\n",
    "    Champion.TARIC,\n",
    "    Champion.POPPY,\n",
    "]\n",
    "\n",
    "# Custom champion pools for my clash team\n",
    "clash_champion_pools = {\n",
    "    \"TOP\": arthur_top_pool,\n",
    "    \"JUNGLE\": filip_jungle_pool,\n",
    "    \"MID\": cyprien_mid_pool,\n",
    "    \"BOT\": geoffroy_bot_pool,\n",
    "    \"UTILITY\": mathias_utility_pool,\n",
    "}\n",
    "\n",
    "# Create custom role matrices\n",
    "clash_role_matrix = create_role_matrix_from_pools(clash_champion_pools)\n",
    "\n",
    "major_patch = 14\n",
    "minor_patch = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the human_vs_human_with_suggestions function with custom role matrices\n",
    "human_vs_human_with_suggestions(\n",
    "    blue_custom_role_matrix=None,\n",
    "    red_custom_role_matrix=clash_role_matrix,\n",
    "    blue_use_fallback=True,  # Set to True to use all champions for blue team\n",
    "    red_use_fallback=False,  # Set to True to use all champions for red team\n",
    "    numeric_patch=major_patch * 50 + minor_patch,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_patch = 14\n",
    "minor_patch = 22\n",
    "\n",
    "visualize_self_play(\n",
    "    num_games=5,\n",
    "    team1_custom_role_matrix=clash_role_matrix,\n",
    "    team1_use_fallback=False,  # Set to True to use all champions for blue team\n",
    "    team2_use_fallback=True,  # Set to True to use all champions for red team\n",
    "    numeric_patch=major_patch * 50 + minor_patch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_vs_human_with_suggestions(\n",
    "    picks_to_watch=filip_utility_pool,\n",
    "    numeric_patch=major_patch * 50 + minor_patch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
