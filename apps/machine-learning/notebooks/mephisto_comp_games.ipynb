{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv format:\n",
    "(.venv) (base) ➜  machine-learning git:(main) ✗ head data/comp-games.csv \n",
    "id,patch_version_substring,region_name,blue_team_name,red_team_name,blue_team_won,schedule_start_time,riot_match_id,blue_top_name,blue_jungle_name,blue_mid_name,blue_bot_name,blue_support_name,red_top_name,red_jungle_name,red_mid_name,red_bot_name,red_support_name\n",
    "5589,15.1,LPL,Weibo Gaming,OMG,1,2025-01-12T08:00:00.000Z,1.13663E+17,KSante,Viego,Aurora,Ashe,Braum,Gnar,Nocturne,Orianna,Varus,Neeko\n",
    "5590,15.1,LPL,OMG,Weibo Gaming,0,2025-01-12T09:00:00.000Z,1.13663E+17,Rumble,Maokai,Ambessa,Jhin,Rell,Jayce,MonkeyKing,Viktor,MissFortune,Rakan\n",
    "5591,15.1,LPL,OMG,Weibo Gaming,0,2025-01-12T10:00:00.000Z,1.13663E+17,Aatrox,Zyra,Yone,Ziggs,Leona,Jax,Sejuani,Sylas,Jinx,Poppy\n",
    "5592,15.1,LPL,LNG Esports,TT Gaming,1,2025-01-13T08:00:00.000Z,113662725452970050,KSante,Pantheon,Vladimir,Kalista,Neeko,Rumble,Vi,Aurora,Ezreal,Leona\n",
    "5593,15.1,LPL,TT Gaming,LNG Esports,1,2025-01-13T09:00:00.000Z,113662725452970050,Gnar,MonkeyKing,Akali,Kaisa,Rakan,Renekton,LeeSin,Taliyah,Corki,Rell\n",
    "5594,15.1,LPL,LNG Esports,TT Gaming,0,2025-01-13T10:00:00.000Z,113662725452970050,Jax,Volibear,Yone,Ashe,Braum,Gragas,XinZhao,Viktor,Varus,Karma\n",
    "5595,15.1,LPL,LNG Esports,TT Gaming,0,2025-01-13T11:00:00.000Z,113662725452970050,Ambessa,Sejuani,Sylas,Twitch,Lulu,Poppy,Viego,Azir,Jinx,Blitzcrank\n",
    "5596,15.1,LPL,Royal Never Give Up,FunPlus Phoenix,0,2025-01-14T08:00:00.000Z,113662725453101140,Jax,Viego,Orianna,Ashe,Braum,KSante,Vi,Aurora,Kalista,Neeko\n",
    "5597,15.1,LPL,Royal Never Give Up,FunPlus Phoenix,1,2025-01-14T09:00:00.000Z,113662725453101140,Ambessa,LeeSin,Akali,Varus,Nautilus,Jayce,MonkeyKing,Sylas,MissFortune,Rakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import re\n",
    "from difflib import get_close_matches\n",
    "\n",
    "from utils.match_prediction.champions import Champion\n",
    "\n",
    "# Constants\n",
    "MODEL_URL = \"http://localhost:8000/predict-batch\"\n",
    "BATCH_SIZE = 2048  # Adjust based on your server's MAX_BATCH_SIZE\n",
    "\n",
    "\n",
    "def format_patch_version(patch: str) -> str:\n",
    "    \"\"\"Convert patch version to have 2 significant digits after decimal.\"\"\"\n",
    "    # Handle cases where there's no decimal point\n",
    "    if \".\" not in patch:\n",
    "        print(f\"WARNING: Invalid patch format found: {patch}\")\n",
    "        return patch  # Return original value if we can't parse it\n",
    "\n",
    "    major, minor = patch.split(\".\")\n",
    "    return f\"{major}.{int(minor):02d}\"\n",
    "\n",
    "\n",
    "# Update the RELEVANT_PATCHES with formatted versions\n",
    "# RELEVANT_PATCHES = [\"15.03\", \"15.04\", \"15.05\"]  # Changed from [\"15.3\", \"15.4\", \"15.5\"]\n",
    "RELEVANT_PATCHES = [\n",
    "    \"15.01\",\n",
    "    \"15.02\",\n",
    "    \"15.03\",\n",
    "    \"15.04\",\n",
    "    \"15.05\",  # Patches from 15.01 to 15.05\n",
    "    \"14.07\",\n",
    "    \"14.08\",\n",
    "    \"14.09\",\n",
    "    \"14.10\",\n",
    "    \"14.11\",\n",
    "    \"14.12\",\n",
    "    \"14.13\",\n",
    "    \"14.14\",\n",
    "    \"14.15\",\n",
    "    \"14.16\",\n",
    "    \"14.17\",\n",
    "    \"14.18\",\n",
    "    \"14.19\",\n",
    "    \"14.20\",\n",
    "    \"14.21\",\n",
    "    \"14.22\",\n",
    "    \"14.23\",\n",
    "    \"14.24\",  # Patches from 14.07 to 14.24\n",
    "]\n",
    "OUTPUT_FILE = \"../data/comp-games-with-predictions.csv\"\n",
    "\n",
    "# Manual name mappings for special cases\n",
    "NAME_OVERRIDES = {\n",
    "    \"MonkeyKing\": \"Wukong\",\n",
    "    \"Nunu\": \"Nunu & Willump\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_champion_mapping() -> Dict[str, int]:\n",
    "    \"\"\"Create a mapping from champion name to ID with alternative names.\"\"\"\n",
    "    champion_mapping = {}\n",
    "\n",
    "    # Create regular mapping\n",
    "    for champion in Champion:\n",
    "        # Lowercase for case-insensitive matching\n",
    "        name = champion.display_name.lower()\n",
    "        champion_mapping[name] = champion.id\n",
    "\n",
    "        # Add name without punctuation and spaces\n",
    "        clean_name = re.sub(r\"[^\\w]\", \"\", name)\n",
    "        champion_mapping[clean_name] = champion.id\n",
    "\n",
    "    # Add special case mappings\n",
    "    for alt_name, actual_name in NAME_OVERRIDES.items():\n",
    "        for champion in Champion:\n",
    "            if champion.display_name.lower() == actual_name.lower():\n",
    "                champion_mapping[alt_name.lower()] = champion.id\n",
    "                break\n",
    "\n",
    "    return champion_mapping\n",
    "\n",
    "\n",
    "def match_champion_name(name: str, mapping: Dict[str, int]) -> Optional[int]:\n",
    "    \"\"\"Match champion name to ID using fuzzy matching if necessary.\"\"\"\n",
    "    name_lower = name.lower()\n",
    "    clean_name = re.sub(r\"[^\\w]\", \"\", name_lower)\n",
    "\n",
    "    # Direct match\n",
    "    if name_lower in mapping:\n",
    "        return mapping[name_lower]\n",
    "\n",
    "    # Clean name match\n",
    "    if clean_name in mapping:\n",
    "        return mapping[clean_name]\n",
    "\n",
    "    # Fuzzy matching\n",
    "    possible_matches = get_close_matches(name_lower, mapping.keys(), n=1, cutoff=0.7)\n",
    "    if possible_matches:\n",
    "        return mapping[possible_matches[0]]\n",
    "\n",
    "    print(f\"WARNING: Could not match champion name: {name}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def prepare_api_input(\n",
    "    row: pd.Series, champion_mapping: Dict[str, int]\n",
    ") -> Optional[Dict]:\n",
    "    \"\"\"Prepare the API input for a single game.\"\"\"\n",
    "    champion_names = [\n",
    "        # Blue team\n",
    "        row[\"blue_top_name\"],\n",
    "        row[\"blue_jungle_name\"],\n",
    "        row[\"blue_mid_name\"],\n",
    "        row[\"blue_bot_name\"],\n",
    "        row[\"blue_support_name\"],\n",
    "        # Red team\n",
    "        row[\"red_top_name\"],\n",
    "        row[\"red_jungle_name\"],\n",
    "        row[\"red_mid_name\"],\n",
    "        row[\"red_bot_name\"],\n",
    "        row[\"red_support_name\"],\n",
    "    ]\n",
    "\n",
    "    # Map champion names to IDs\n",
    "    champion_ids = []\n",
    "    for name in champion_names:\n",
    "        champ_id = match_champion_name(name, champion_mapping)\n",
    "        if champ_id is None:\n",
    "            return None  # Skip if any champion can't be matched\n",
    "        champion_ids.append(champ_id)\n",
    "\n",
    "    # Return the API input\n",
    "    return {\n",
    "        \"champion_ids\": champion_ids,\n",
    "        \"numerical_elo\": 0,  # Diamond 2 +\n",
    "        \"patch\": row[\"patch_version_substring\"],\n",
    "        # TODO: it actually has better accuraccy on queue 420?\n",
    "        \"queueId\": 420,\n",
    "        # \"queueId\": 700,\n",
    "    }\n",
    "\n",
    "\n",
    "def send_batch_predictions(api_inputs: List[Dict]) -> List[float]:\n",
    "    \"\"\"Send a batch of predictions to the model server.\"\"\"\n",
    "    try:\n",
    "        # Add API key in the header\n",
    "        headers = {\"X-API-Key\": \"example_token\"}\n",
    "        response = requests.post(MODEL_URL, json=api_inputs, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return [pred[\"win_probability\"] for pred in response.json()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending batch prediction: {e}\")\n",
    "        print(f\"Request payload: {json.dumps(api_inputs)}\")\n",
    "        # Return None for each input in case of error\n",
    "        return [None] * len(api_inputs)\n",
    "\n",
    "\n",
    "def evaluate_model(df: pd.DataFrame) -> Tuple[float, float]:\n",
    "    \"\"\"Calculate log loss and accuracy for model predictions.\"\"\"\n",
    "    # Filter out rows with missing predictions\n",
    "    eval_df = df[df[\"model_prediction\"].notna()].copy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    y_true = eval_df[\"blue_team_won\"].astype(int)\n",
    "    y_pred = eval_df[\"model_prediction\"]\n",
    "\n",
    "    # Convert probabilities to binary predictions using 0.5 threshold\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    loss = log_loss(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred_binary)\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(\"../data/comp-games.csv\")\n",
    "\n",
    "    # Filter for relevant patches - fixed to handle numeric patch versions\n",
    "    print(f\"Filtering for patches: {RELEVANT_PATCHES}\")\n",
    "\n",
    "    # Format the patch versions in the dataframe\n",
    "    df[\"patch_version_substring\"] = (\n",
    "        df[\"patch_version_substring\"].astype(str).apply(format_patch_version)\n",
    "    )\n",
    "    patch_pattern = \"|\".join(RELEVANT_PATCHES)\n",
    "    df = df[df[\"patch_version_substring\"].str.match(patch_pattern)]\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print(f\"No games found for patches {RELEVANT_PATCHES}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(df)} games for evaluation\")\n",
    "\n",
    "    # Load champion mapping\n",
    "    champion_mapping = load_champion_mapping()\n",
    "\n",
    "    # Prepare inputs for all games\n",
    "    api_inputs = []\n",
    "    valid_indices = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        api_input = prepare_api_input(row, champion_mapping)\n",
    "        if api_input is not None:\n",
    "            api_inputs.append(api_input)\n",
    "            valid_indices.append(idx)\n",
    "\n",
    "    print(f\"Prepared {len(api_inputs)} valid inputs for prediction\")\n",
    "\n",
    "    # Initialize predictions array\n",
    "    all_predictions = np.full(len(df), np.nan)\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, len(api_inputs), BATCH_SIZE):\n",
    "        batch_inputs = api_inputs[i : i + BATCH_SIZE]\n",
    "        batch_indices = valid_indices[i : i + BATCH_SIZE]\n",
    "\n",
    "        print(\n",
    "            f\"Processing batch {i//BATCH_SIZE + 1}/{(len(api_inputs) + BATCH_SIZE - 1)//BATCH_SIZE}\"\n",
    "        )\n",
    "        batch_predictions = send_batch_predictions(batch_inputs)\n",
    "\n",
    "        # Store predictions\n",
    "        for idx, pred in zip(batch_indices, batch_predictions):\n",
    "            if pred is not None:\n",
    "                all_predictions[df.index.get_indexer([idx])[0]] = pred\n",
    "\n",
    "    # Add predictions to dataframe\n",
    "    df[\"model_prediction\"] = all_predictions\n",
    "\n",
    "    # Evaluate model\n",
    "    filtered_df = df[df[\"model_prediction\"].notna()]\n",
    "    if len(filtered_df) > 0:\n",
    "        loss, acc = evaluate_model(filtered_df)\n",
    "        print(f\"\\nModel evaluation on {len(filtered_df)} games:\")\n",
    "        print(f\"Log Loss: {loss:.4f}\")\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "        # Add a column that indicates if model prediction is correct\n",
    "        filtered_df[\"model_correct\"] = (\n",
    "            (filtered_df[\"model_prediction\"] > 0.5)\n",
    "            == (filtered_df[\"blue_team_won\"] == 1)\n",
    "        ).astype(int)\n",
    "    else:\n",
    "        print(\"No valid predictions to evaluate\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    filtered_df.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"Results saved to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Filtering for patches: ['15.01', '15.02', '15.03', '15.04', '15.05', '14.07', '14.08', '14.09', '14.10', '14.11', '14.12', '14.13', '14.14', '14.15', '14.16', '14.17', '14.18', '14.19', '14.20', '14.21', '14.22', '14.23', '14.24']\n",
      "WARNING: Invalid patch format found: nan\n",
      "WARNING: Invalid patch format found: nan\n",
      "WARNING: Invalid patch format found: nan\n",
      "WARNING: Invalid patch format found: nan\n",
      "WARNING: Invalid patch format found: nan\n",
      "WARNING: Invalid patch format found: nan\n",
      "Found 3157 games for evaluation\n",
      "Prepared 3157 valid inputs for prediction\n",
      "Processing batch 1/2\n",
      "Processing batch 2/2\n",
      "\n",
      "Model evaluation on 3157 games:\n",
      "Log Loss: 0.6964\n",
      "Accuracy: 0.5322\n",
      "Results saved to ../data/comp-games-with-predictions.csv\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
