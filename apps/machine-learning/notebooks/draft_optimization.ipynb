{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft Optimization\n",
    "\n",
    "This notebook evaluates champion combinations using the local LoL draft prediction model to find the optimal team compositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from utils.rl.champions import Champion\n",
    "\n",
    "# Load API key once at the start\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "HEADERS = {\"X-API-Key\": API_KEY} if API_KEY else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = \"15.04\"\n",
    "numerical_elo = 0  # highest numerical elo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Champion Pools\n",
    "\n",
    "Define the champion pools for each role. Starting with 3 champions per role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Could also do combinations for ennemy champions, but understand that they should be limited: probably against key meta champions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los ratones champion pools\n",
    "champion_pools = {\n",
    "    \"TOP\": [\n",
    "        Champion.JAX,\n",
    "        Champion.SION,\n",
    "        Champion.VOLIBEAR,\n",
    "        Champion.GRAGAS,\n",
    "        Champion.QUINN,\n",
    "        Champion.CHOGATH,\n",
    "        Champion.GAREN,\n",
    "        Champion.POPPY,\n",
    "        Champion.VI,\n",
    "        Champion.AMBESSA,\n",
    "    ],\n",
    "    \"JUNGLE\": [\n",
    "        Champion.JARVAN_IV,\n",
    "        Champion.VIEGO,\n",
    "        Champion.WUKONG,\n",
    "        Champion.PANTHEON,\n",
    "        Champion.VI,\n",
    "        Champion.IVERN,\n",
    "        Champion.MAOKAI,\n",
    "    ],\n",
    "    \"MID\": [\n",
    "        Champion.GALIO,\n",
    "        Champion.ORIANNA,\n",
    "        Champion.AZIR,\n",
    "        Champion.SYNDRA,\n",
    "        Champion.AHRI,\n",
    "        Champion.VIKTOR,\n",
    "        Champion.HWEI,\n",
    "        Champion.MEL,\n",
    "        Champion.ZILEAN,\n",
    "        Champion.CHOGATH,\n",
    "    ],\n",
    "    \"BOT\": [\n",
    "        Champion.CORKI,\n",
    "        Champion.EZREAL,\n",
    "        Champion.JINX,\n",
    "        Champion.KALISTA,\n",
    "        Champion.TRISTANA,\n",
    "        Champion.ZERI,\n",
    "        Champion.SIVIR,\n",
    "        Champion.XAYAH,\n",
    "    ],\n",
    "    \"SUPPORT\": [\n",
    "        Champion.BRAUM,\n",
    "        Champion.JANNA,\n",
    "        Champion.RAKAN,\n",
    "        Champion.RELL,\n",
    "        Champion.ALISTAR,\n",
    "        Champion.RENATA_GLASC,\n",
    "        Champion.LULU,\n",
    "        Champion.MILIO,\n",
    "        Champion.BARD,\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create lookup dictionaries\n",
    "id_to_name = {champion.id: champion.display_name for champion in Champion}\n",
    "name_to_id = {champion.display_name: champion.id for champion in Champion}\n",
    "\n",
    "# Display the champion pools\n",
    "for role, champions in champion_pools.items():\n",
    "    print(f\"{role}: {', '.join([champion.display_name for champion in champions])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Team Compositions\n",
    "\n",
    "Generate all possible team compositions from the champion pools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_team_comps(champion_pools):\n",
    "    \"\"\"\n",
    "    Generate all possible team compositions from the champion pools,\n",
    "    excluding compositions where the same champion appears in multiple roles.\n",
    "\n",
    "    Args:\n",
    "        champion_pools: Dictionary of champion pools for each role\n",
    "\n",
    "    Returns:\n",
    "        List of team compositions, where each composition is a list of 5 unique champion objects\n",
    "    \"\"\"\n",
    "    roles = [\"TOP\", \"JUNGLE\", \"MID\", \"BOT\", \"SUPPORT\"]\n",
    "    # Generate all possible combinations\n",
    "    all_comps = list(itertools.product(*[champion_pools[role] for role in roles]))\n",
    "\n",
    "    # Filter out compositions with duplicate champions\n",
    "    valid_comps = []\n",
    "    for comp in all_comps:\n",
    "        # Create a set of champion IDs to check for uniqueness\n",
    "        champion_ids = {champion.id for champion in comp}\n",
    "        # If we have 5 unique champions, this is a valid composition\n",
    "        if len(champion_ids) == 5:\n",
    "            valid_comps.append(comp)\n",
    "\n",
    "    return valid_comps\n",
    "\n",
    "\n",
    "# Generate all possible team compositions\n",
    "team_comps = generate_team_comps(champion_pools)\n",
    "print(f\"Generated {len(team_comps)} possible team compositions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model Prediction Functions\n",
    "\n",
    "Create functions to get predictions from the model API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(champion_ids, side=\"blue\"):\n",
    "    \"\"\"\n",
    "    Get winrate prediction for a team composition.\n",
    "\n",
    "    Args:\n",
    "        champion_ids: List of 5 champion IDs for the team\n",
    "        side: 'blue' or 'red'\n",
    "\n",
    "    Returns:\n",
    "        Winrate prediction (0-1)\n",
    "    \"\"\"\n",
    "    # Create the full 10-champion array with UNKNOWNs for the opponent team\n",
    "    full_champion_ids = []\n",
    "\n",
    "    if side == \"blue\":\n",
    "        # Team on blue side (positions 0-4)\n",
    "        full_champion_ids = champion_ids + [\"UNKNOWN\"] * 5\n",
    "    else:\n",
    "        # Team on red side (positions 5-9)\n",
    "        full_champion_ids = [\"UNKNOWN\"] * 5 + champion_ids\n",
    "\n",
    "    # Prepare the API request\n",
    "    api_input = {\n",
    "        \"champion_ids\": full_champion_ids,\n",
    "        \"numerical_elo\": numerical_elo,\n",
    "        \"patch\": patch,\n",
    "    }\n",
    "\n",
    "    # Make the API request\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"http://0.0.0.0:8000/predict\", json=api_input, headers=HEADERS\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        if side == \"blue\":\n",
    "            return response.json()[\"win_probability\"]\n",
    "        elif side == \"red\":\n",
    "            return 1 - response.json()[\"win_probability\"]\n",
    "        else:\n",
    "            raise ValueError(\"invalide side\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error making prediction: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Team Compositions\n",
    "\n",
    "Evaluate all team compositions by checking their winrates on both blue and red sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all team compositions\n",
    "def evaluate_team_comps():\n",
    "    results = []\n",
    "\n",
    "    # Use tqdm for a progress bar\n",
    "    for comp in tqdm(team_comps, desc=\"Evaluating team compositions\"):\n",
    "        # Extract champion IDs\n",
    "        champion_ids = [champion.id for champion in comp]\n",
    "        champion_names = [champion.display_name for champion in comp]\n",
    "\n",
    "        # Get predictions for both sides\n",
    "        blue_winrate = get_prediction(champion_ids, side=\"blue\")\n",
    "        red_winrate = get_prediction(champion_ids, side=\"red\")\n",
    "\n",
    "        if blue_winrate is not None and red_winrate is not None:\n",
    "            # Calculate average winrate\n",
    "            avg_winrate = (blue_winrate + red_winrate) / 2\n",
    "\n",
    "            # Create a result entry\n",
    "            result = {\n",
    "                \"TOP\": champion_names[0],\n",
    "                \"JUNGLE\": champion_names[1],\n",
    "                \"MID\": champion_names[2],\n",
    "                \"BOT\": champion_names[3],\n",
    "                \"SUPPORT\": champion_names[4],\n",
    "                \"blue_winrate\": blue_winrate,\n",
    "                \"red_winrate\": red_winrate,\n",
    "                \"avg_winrate\": avg_winrate,\n",
    "            }\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Run the evaluation\n",
    "# results = evaluate_team_comps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Batch Processing\n",
    "\n",
    "Here's an optimized version that uses batched API calls for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for batched processing (uncomment to use after confirming the simple version works)\n",
    "def evaluate_team_comps_batched():\n",
    "    # Create a list to hold all API requests we need to make\n",
    "    all_requests = []\n",
    "\n",
    "    # For each composition, we need to evaluate it on both blue and red side\n",
    "    for idx, comp in enumerate(team_comps):\n",
    "        champion_ids = [champion.id for champion in comp]\n",
    "\n",
    "        # Request for blue side (comp is on blue side)\n",
    "        blue_request = {\n",
    "            \"champion_ids\": champion_ids + [\"UNKNOWN\"] * 5,\n",
    "            \"numerical_elo\": numerical_elo,\n",
    "            \"patch\": patch,\n",
    "        }\n",
    "\n",
    "        # Request for red side (comp is on red side)\n",
    "        red_request = {\n",
    "            \"champion_ids\": [\"UNKNOWN\"] * 5 + champion_ids,\n",
    "            \"numerical_elo\": numerical_elo,\n",
    "            \"patch\": patch,\n",
    "        }\n",
    "\n",
    "        # Add to our request list with metadata\n",
    "        all_requests.append((blue_request, \"blue\", idx))\n",
    "        all_requests.append((red_request, \"red\", idx))\n",
    "\n",
    "    # Organize results\n",
    "    blue_results = {}\n",
    "    red_results = {}\n",
    "\n",
    "    # Process in batches\n",
    "    BATCH_SIZE = 16\n",
    "    with tqdm(total=len(all_requests), desc=\"Making batch API calls\") as pbar:\n",
    "        for i in range(0, len(all_requests), BATCH_SIZE):\n",
    "            batch = all_requests[i : i + BATCH_SIZE]\n",
    "\n",
    "            # Extract just the API requests\n",
    "            api_requests = [req[0] for req in batch]\n",
    "\n",
    "            # Make the batch API call\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    \"http://0.0.0.0:8000/predict-batch\",\n",
    "                    json=api_requests,\n",
    "                    headers=HEADERS,\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "\n",
    "                # Process results\n",
    "                for (_, side, idx), prediction in zip(batch, response.json()):\n",
    "                    winrate = prediction[\"win_probability\"]\n",
    "\n",
    "                    if side == \"blue\":\n",
    "                        blue_results[idx] = winrate\n",
    "                    else:\n",
    "                        red_results[idx] = 1 - winrate\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in batch processing: {e}\")\n",
    "\n",
    "            pbar.update(len(batch))\n",
    "\n",
    "    # Combine results\n",
    "    results = []\n",
    "    for idx, comp in enumerate(team_comps):\n",
    "        if idx in blue_results and idx in red_results:\n",
    "            champion_names = [champion.display_name for champion in comp]\n",
    "            champion_ids_list = [champion.id for champion in comp]\n",
    "            blue_winrate = blue_results[idx]\n",
    "            red_winrate = red_results[idx]\n",
    "            avg_winrate = (blue_winrate + red_winrate) / 2\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"TOP\": champion_names[0],\n",
    "                    \"JUNGLE\": champion_names[1],\n",
    "                    \"MID\": champion_names[2],\n",
    "                    \"BOT\": champion_names[3],\n",
    "                    \"SUPPORT\": champion_names[4],\n",
    "                    \"TOP_ID\": champion_ids_list[0],\n",
    "                    \"JUNGLE_ID\": champion_ids_list[1],\n",
    "                    \"MID_ID\": champion_ids_list[2],\n",
    "                    \"BOT_ID\": champion_ids_list[3],\n",
    "                    \"SUPPORT_ID\": champion_ids_list[4],\n",
    "                    \"blue_winrate\": blue_winrate,\n",
    "                    \"red_winrate\": red_winrate,\n",
    "                    \"avg_winrate\": avg_winrate,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Uncomment to use the batched version instead\n",
    "results = evaluate_team_comps_batched()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results\n",
    "\n",
    "Create a DataFrame with the results and display the top team compositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from results\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by average winrate\n",
    "df = df.sort_values(by='avg_winrate', ascending=False)\n",
    "\n",
    "# Display top 10 compositions\n",
    "print(\"Top 10 Team Compositions:\")\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def create_enhanced_browser(df):\n",
    "    # Create filter widgets for each role\n",
    "    include_filters = {}\n",
    "    exclude_filters = {}\n",
    "    \n",
    "    for role in ['TOP', 'JUNGLE', 'MID', 'BOT', 'SUPPORT']:\n",
    "        # Get unique champions for this role\n",
    "        unique_champs = sorted(df[role].unique())\n",
    "        \n",
    "        # Create include filter (without description to fix alignment)\n",
    "        include_filters[role] = widgets.SelectMultiple(\n",
    "            options=unique_champs,\n",
    "            layout=widgets.Layout(width='180px', height='120px')\n",
    "        )\n",
    "        \n",
    "        # Create exclude filter (without description to fix alignment)\n",
    "        exclude_filters[role] = widgets.SelectMultiple(\n",
    "            options=unique_champs,\n",
    "            layout=widgets.Layout(width='180px', height='120px')\n",
    "        )\n",
    "    \n",
    "    # Create pagination controls\n",
    "    page_size = widgets.BoundedIntText(\n",
    "        value=10,\n",
    "        min=1,\n",
    "        max=100,\n",
    "        description='Page size:',\n",
    "        layout=widgets.Layout(width='150px')\n",
    "    )\n",
    "    \n",
    "    current_page = widgets.BoundedIntText(\n",
    "        value=1,\n",
    "        min=1,\n",
    "        description='Page:',\n",
    "        layout=widgets.Layout(width='150px')\n",
    "    )\n",
    "    \n",
    "    prev_button = widgets.Button(\n",
    "        description='Previous',\n",
    "        layout=widgets.Layout(width='100px')\n",
    "    )\n",
    "    \n",
    "    next_button = widgets.Button(\n",
    "        description='Next',\n",
    "        layout=widgets.Layout(width='100px')\n",
    "    )\n",
    "    \n",
    "    # Create output area for displaying results\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Clear filter buttons for each role\n",
    "    clear_buttons = {}\n",
    "    for role in ['TOP', 'JUNGLE', 'MID', 'BOT', 'SUPPORT']:\n",
    "        clear_buttons[role] = widgets.Button(\n",
    "            description='Clear Filters',\n",
    "            layout=widgets.Layout(width='180px')\n",
    "        )\n",
    "    \n",
    "    # Function to apply filters and update display\n",
    "    def update_display():\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Apply filters for each role\n",
    "            filtered_df = df.copy()\n",
    "            \n",
    "            for role in ['TOP', 'JUNGLE', 'MID', 'BOT', 'SUPPORT']:\n",
    "                include_champs = list(include_filters[role].value)\n",
    "                exclude_champs = list(exclude_filters[role].value)\n",
    "                \n",
    "                # Apply include filter (if any champions selected)\n",
    "                if include_champs:\n",
    "                    filtered_df = filtered_df[filtered_df[role].isin(include_champs)]\n",
    "                \n",
    "                # Apply exclude filter (if any champions selected)\n",
    "                if exclude_champs:\n",
    "                    filtered_df = filtered_df[~filtered_df[role].isin(exclude_champs)]\n",
    "            \n",
    "            # Calculate total pages\n",
    "            total_rows = len(filtered_df)\n",
    "            total_pages = max(1, (total_rows + page_size.value - 1) // page_size.value)\n",
    "            \n",
    "            # Update current page if needed\n",
    "            if current_page.value > total_pages:\n",
    "                current_page.value = total_pages\n",
    "            \n",
    "            # Calculate slice for current page\n",
    "            start_idx = (current_page.value - 1) * page_size.value\n",
    "            end_idx = min(start_idx + page_size.value, total_rows)\n",
    "            \n",
    "            # Display pagination info\n",
    "            print(f\"Showing {start_idx+1}-{end_idx} of {total_rows} results (Page {current_page.value} of {total_pages})\")\n",
    "            \n",
    "            # Display the filtered and paginated data\n",
    "            if total_rows > 0:\n",
    "                display(filtered_df.iloc[start_idx:end_idx])\n",
    "            else:\n",
    "                print(\"No results match your filters.\")\n",
    "    \n",
    "    # Connect button events\n",
    "    def on_prev_click(b):\n",
    "        if current_page.value > 1:\n",
    "            current_page.value -= 1\n",
    "            update_display()\n",
    "    \n",
    "    def on_next_click(b):\n",
    "        # The max value will be calculated in update_display\n",
    "        current_page.value += 1\n",
    "        update_display()\n",
    "    \n",
    "    # Create clear filter handlers\n",
    "    def create_clear_handler(role):\n",
    "        def clear_handler(b):\n",
    "            include_filters[role].value = ()\n",
    "            exclude_filters[role].value = ()\n",
    "            update_display()\n",
    "        return clear_handler\n",
    "    \n",
    "    # Connect events\n",
    "    prev_button.on_click(on_prev_click)\n",
    "    next_button.on_click(on_next_click)\n",
    "    \n",
    "    # Connect clear buttons\n",
    "    for role in clear_buttons:\n",
    "        clear_buttons[role].on_click(create_clear_handler(role))\n",
    "    \n",
    "    # Update when any filter or pagination control changes\n",
    "    for role in include_filters:\n",
    "        include_filters[role].observe(lambda change: update_display(), names='value')\n",
    "        exclude_filters[role].observe(lambda change: update_display(), names='value')\n",
    "    \n",
    "    page_size.observe(lambda change: update_display(), names='value')\n",
    "    current_page.observe(lambda change: update_display(), names='value')\n",
    "    \n",
    "    # Create layout\n",
    "    filter_boxes = []\n",
    "    for role in ['TOP', 'JUNGLE', 'MID', 'BOT', 'SUPPORT']:\n",
    "        # Create proper headers with HTML\n",
    "        include_header = widgets.HTML(value=f\"<b>Include {role}:</b>\")\n",
    "        exclude_header = widgets.HTML(value=f\"<b>Exclude {role}:</b>\")\n",
    "        \n",
    "        # Layout each role's filters in a vertical box\n",
    "        filter_box = widgets.VBox([\n",
    "            widgets.HTML(value=f\"<h4>{role}</h4>\"),\n",
    "            include_header,\n",
    "            include_filters[role],\n",
    "            exclude_header,\n",
    "            exclude_filters[role],\n",
    "            clear_buttons[role]\n",
    "        ], layout=widgets.Layout(margin='0px', padding='0px'))\n",
    "        \n",
    "        filter_boxes.append(filter_box)\n",
    "    \n",
    "    filters_row = widgets.HBox(filter_boxes, layout=widgets.Layout(margin='0px', padding='0px'))\n",
    "    \n",
    "    pagination_row = widgets.HBox([\n",
    "        page_size,\n",
    "        current_page,\n",
    "        prev_button,\n",
    "        next_button\n",
    "    ])\n",
    "    \n",
    "    # Main layout\n",
    "    main_layout = widgets.VBox([\n",
    "        widgets.HTML(value=\"<h3>Team Composition Browser</h3>\"),\n",
    "        filters_row,\n",
    "        pagination_row,\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    # Initial display\n",
    "    display(main_layout)\n",
    "    update_display()\n",
    "\n",
    "# Use the function with your results DataFrame\n",
    "create_enhanced_browser(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to SQLite with champion IDs\n",
    "import sqlite3\n",
    "\n",
    "# Create SQLite database\n",
    "db_path = \"lol_team_compositions.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Create table with proper indices including champion IDs\n",
    "conn.execute(\n",
    "    \"\"\"\n",
    "CREATE TABLE team_comps (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    TOP TEXT NOT NULL,\n",
    "    JUNGLE TEXT NOT NULL, \n",
    "    MID TEXT NOT NULL,\n",
    "    BOT TEXT NOT NULL,\n",
    "    SUPPORT TEXT NOT NULL,\n",
    "    TOP_ID TEXT NOT NULL,\n",
    "    JUNGLE_ID TEXT NOT NULL,\n",
    "    MID_ID TEXT NOT NULL,\n",
    "    BOT_ID TEXT NOT NULL,\n",
    "    SUPPORT_ID TEXT NOT NULL,\n",
    "    blue_winrate REAL NOT NULL,\n",
    "    red_winrate REAL NOT NULL,\n",
    "    avg_winrate REAL NOT NULL\n",
    ")\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create indices for faster filtering\n",
    "conn.execute(\"CREATE INDEX idx_top ON team_comps(TOP)\")\n",
    "conn.execute(\"CREATE INDEX idx_jungle ON team_comps(JUNGLE)\")\n",
    "conn.execute(\"CREATE INDEX idx_mid ON team_comps(MID)\")\n",
    "conn.execute(\"CREATE INDEX idx_bot ON team_comps(BOT)\")\n",
    "conn.execute(\"CREATE INDEX idx_support ON team_comps(SUPPORT)\")\n",
    "conn.execute(\"CREATE INDEX idx_top_id ON team_comps(TOP_ID)\")\n",
    "conn.execute(\"CREATE INDEX idx_jungle_id ON team_comps(JUNGLE_ID)\")\n",
    "conn.execute(\"CREATE INDEX idx_mid_id ON team_comps(MID_ID)\")\n",
    "conn.execute(\"CREATE INDEX idx_bot_id ON team_comps(BOT_ID)\")\n",
    "conn.execute(\"CREATE INDEX idx_support_id ON team_comps(SUPPORT_ID)\")\n",
    "conn.execute(\"CREATE INDEX idx_avg_winrate ON team_comps(avg_winrate)\")\n",
    "\n",
    "# Insert data\n",
    "df.to_sql(\"team_comps\", conn, if_exists=\"append\", index=False)\n",
    "\n",
    "# Commit and close\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(f\"SQLite database created at: {db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
