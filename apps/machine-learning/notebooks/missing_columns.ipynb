{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect raw dataframes to understand column structure\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import random  # Added for random sampling\n",
    "from pprint import pprint\n",
    "\n",
    "# Configure these to match your environment\n",
    "RAW_DATA_DIR = \"/Users/loyd/draftking/apps/machine-learning/data/raw_azure\"\n",
    "NUM_FILES_TO_CHECK = 3  # Number of files to examine\n",
    "\n",
    "\n",
    "# Function to load data from parquet\n",
    "def load_data(file_path):\n",
    "    return pd.read_parquet(file_path)\n",
    "\n",
    "\n",
    "# Get list of parquet files\n",
    "input_files = glob.glob(os.path.join(RAW_DATA_DIR, \"*.parquet\"))\n",
    "\n",
    "print(f\"Found {len(input_files)} parquet files\")\n",
    "\n",
    "# Dictionary to track findings\n",
    "file_findings = {}\n",
    "\n",
    "# Check specific columns we're interested in\n",
    "columns_to_check = [\n",
    "    \"totalGold_at_900000_TOP_100\",\n",
    "    \"deaths_at_900000_TOP_100\",\n",
    "    \"creepScore_at_900000_TOP_100\",\n",
    "    \"level_at_900000_TOP_100\",\n",
    "    \"team_TOP_100_totalGold_at_900000\",  # Alternative format\n",
    "    \"team_100_TOP_totalGold_at_900000\",  # Another alternative format\n",
    "]\n",
    "\n",
    "# Randomly sample files instead of taking the first few\n",
    "random_files = random.sample(input_files, min(NUM_FILES_TO_CHECK, len(input_files)))\n",
    "\n",
    "# Load and examine the randomly selected files\n",
    "for i, file_path in enumerate(random_files):\n",
    "    print(f\"\\n----- File {i+1}: {os.path.basename(file_path)} -----\")\n",
    "\n",
    "    df = load_data(file_path)\n",
    "\n",
    "    # Basic info\n",
    "    print(f\"Rows: {len(df)}\")\n",
    "    print(f\"Total columns: {len(df.columns)}\")\n",
    "\n",
    "    # Check for our expected columns\n",
    "    found_columns = [col for col in columns_to_check if col in df.columns]\n",
    "    print(f\"Found {len(found_columns)} of our expected columns\")\n",
    "\n",
    "    # Look for pattern matches\n",
    "    time_related_cols = [col for col in df.columns if \"900000\" in col]\n",
    "    print(f\"Time-related columns (900000): {len(time_related_cols)}\")\n",
    "\n",
    "    gold_related_cols = [col for col in df.columns if \"Gold\" in col or \"gold\" in col]\n",
    "    print(f\"Gold-related columns: {len(gold_related_cols)}\")\n",
    "\n",
    "    # Find columns that might have timeline data\n",
    "    timeline_cols = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if any(time in col for time in [\"at_\", \"At\", \"time\", \"Time\"])\n",
    "    ]\n",
    "    print(f\"Possible timeline columns: {len(timeline_cols)}\")\n",
    "\n",
    "    # Display sample data - columns related to game stats\n",
    "    role_cols = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if any(role in col for role in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"])\n",
    "    ]\n",
    "    print(f\"Role-related columns: {len(role_cols)}\")\n",
    "\n",
    "    # Show some actual column names as examples\n",
    "    print(\"\\nSample column names:\")\n",
    "    if role_cols:\n",
    "        print(\"Role-related columns:\", role_cols[:5])\n",
    "    if time_related_cols:\n",
    "        print(\"Time-related columns:\", time_related_cols[:5])\n",
    "    if gold_related_cols:\n",
    "        print(\"Gold-related columns:\", gold_related_cols[:5])\n",
    "\n",
    "    # Look at actual data structure\n",
    "    if len(df) > 0:\n",
    "        print(\"\\nFirst row column keys that might contain timeline data:\")\n",
    "        # Look for nested structures or complex objects\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                val = df[col].iloc[0]\n",
    "                if isinstance(val, (dict, list)) or \"timeline\" in str(col).lower():\n",
    "                    print(f\"Column: {col}, Type: {type(val)}\")\n",
    "                    if isinstance(val, dict) and len(val) < 10:\n",
    "                        print(f\"  Content: {val}\")\n",
    "                    elif isinstance(val, list) and len(val) < 10:\n",
    "                        print(f\"  Content: {val}\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Store our findings\n",
    "    file_findings[os.path.basename(file_path)] = {\n",
    "        \"row_count\": len(df),\n",
    "        \"column_count\": len(df.columns),\n",
    "        \"has_expected_columns\": len(found_columns) > 0,\n",
    "        \"gold_columns\": len(gold_related_cols),\n",
    "        \"timeline_columns\": len(timeline_cols),\n",
    "        \"role_columns\": len(role_cols),\n",
    "    }\n",
    "\n",
    "# Summary\n",
    "print(\"\\n===== SUMMARY =====\")\n",
    "print(f\"Examined {NUM_FILES_TO_CHECK} files\")\n",
    "files_with_expected_cols = sum(\n",
    "    1 for f in file_findings.values() if f[\"has_expected_columns\"]\n",
    ")\n",
    "print(f\"Files with expected columns: {files_with_expected_cols}/{NUM_FILES_TO_CHECK}\")\n",
    "\n",
    "# If we found nested timelines, suggest how to access them\n",
    "if any(\n",
    "    \"timeline\" in \" \".join(df.columns).lower()\n",
    "    for df in [load_data(f) for f in input_files[:NUM_FILES_TO_CHECK]]\n",
    "):\n",
    "    print(\n",
    "        \"\\nPOTENTIAL SOLUTION: The raw data appears to have timeline information in nested structures.\"\n",
    "    )\n",
    "    print(\"You may need to extract the timeline data first before applying filters.\")\n",
    "    print(\n",
    "        \"Try examining the timeline columns to see how to extract the 15-minute stats.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
