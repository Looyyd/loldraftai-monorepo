{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft Optimization\n",
    "\n",
    "This notebook evaluates champion combinations using the local LoL draft prediction model to find the optimal team compositions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from utils.rl.champions import Champion\n",
    "\n",
    "# Load API key once at the start\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "HEADERS = {\"X-API-Key\": API_KEY} if API_KEY else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = \"15.04\"\n",
    "numerical_elo = 0  # highest numerical elo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Champion Pools\n",
    "\n",
    "Define the champion pools for each role. Starting with 3 champions per role.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Could also do combinations for ennemy champions, but understand that they should be limited: probably against key meta champions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los ratones champion pools\n",
    "champion_pools = {\n",
    "    \"TOP\": [\n",
    "        \"UNKNOWN\",\n",
    "        Champion.JAX,\n",
    "        Champion.SION,\n",
    "        Champion.VOLIBEAR,\n",
    "        Champion.GRAGAS,\n",
    "        Champion.QUINN,\n",
    "        Champion.CHOGATH,\n",
    "        Champion.GAREN,\n",
    "        Champion.POPPY,\n",
    "        Champion.VI,\n",
    "        Champion.AMBESSA,\n",
    "        Champion.GANGPLANK,\n",
    "    ],\n",
    "    \"JUNGLE\": [\n",
    "        \"UNKNOWN\",\n",
    "        Champion.JARVAN_IV,\n",
    "        Champion.VIEGO,\n",
    "        Champion.WUKONG,\n",
    "        Champion.PANTHEON,\n",
    "        Champion.VI,\n",
    "        Champion.IVERN,\n",
    "        Champion.MAOKAI,\n",
    "    ],\n",
    "    \"MID\": [\n",
    "        \"UNKNOWN\",\n",
    "        Champion.GALIO,\n",
    "        Champion.ORIANNA,\n",
    "        Champion.AZIR,\n",
    "        Champion.SYNDRA,\n",
    "        Champion.AHRI,\n",
    "        Champion.VIKTOR,\n",
    "        Champion.HWEI,\n",
    "        Champion.MEL,\n",
    "        Champion.ZILEAN,\n",
    "        Champion.CHOGATH,\n",
    "        Champion.VEL_KOZ,\n",
    "    ],\n",
    "    \"BOT\": [\n",
    "        \"UNKNOWN\",\n",
    "        Champion.CORKI,\n",
    "        Champion.EZREAL,\n",
    "        Champion.JINX,\n",
    "        Champion.KALISTA,\n",
    "        Champion.TRISTANA,\n",
    "        Champion.ZERI,\n",
    "        Champion.SIVIR,\n",
    "        Champion.XAYAH,\n",
    "        Champion.ZIGGS,\n",
    "    ],\n",
    "    \"SUPPORT\": [\n",
    "        \"UNKNOWN\",\n",
    "        Champion.BRAUM,\n",
    "        Champion.JANNA,\n",
    "        Champion.RAKAN,\n",
    "        Champion.RELL,\n",
    "        Champion.ALISTAR,\n",
    "        Champion.RENATA_GLASC,\n",
    "        Champion.LULU,\n",
    "        Champion.MILIO,\n",
    "    ],\n",
    "}\n",
    "\n",
    "enemy_champion_pools = {\n",
    "    \"TOP\": [\"UNKNOWN\"],\n",
    "    \"JUNGLE\": [\"UNKNOWN\", Champion.VI, Champion.IVERN, Champion.MAOKAI],\n",
    "    \"MID\": [\"UNKNOWN\"],\n",
    "    \"BOT\": [\"UNKNOWN\", Champion.KALISTA, Champion.EZREAL, Champion.DRAVEN],\n",
    "    \"SUPPORT\": [\n",
    "        \"UNKNOWN\",\n",
    "        Champion.BRAUM,\n",
    "        Champion.BLITZCRANK,\n",
    "        Champion.THRESH,\n",
    "        Champion.JANNA,\n",
    "        Champion.RAKAN,\n",
    "        Champion.RELL,\n",
    "        Champion.ALISTAR,\n",
    "        Champion.RENATA_GLASC,\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create lookup dictionaries\n",
    "id_to_name = {champion.id: champion.display_name for champion in Champion}\n",
    "name_to_id = {champion.display_name: champion.id for champion in Champion}\n",
    "\n",
    "# Display the champion pools\n",
    "for role, champions in champion_pools.items():\n",
    "    champions_display = [\n",
    "        champion.display_name if isinstance(champion, Champion) else champion\n",
    "        for champion in champions\n",
    "    ]\n",
    "    print(f\"ALLY {role}: {', '.join(champions_display)}\")\n",
    "\n",
    "for role, champions in enemy_champion_pools.items():\n",
    "    champions_display = [\n",
    "        champion.display_name if isinstance(champion, Champion) else champion\n",
    "        for champion in champions\n",
    "    ]\n",
    "    print(f\"ENEMY {role}: {', '.join(champions_display)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model Prediction Functions\n",
    "\n",
    "Create functions to get predictions from the model API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batched memory efficient version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to include the generate_team_comps_stream function and estimate_max_compositions function\n",
    "def generate_team_comps_stream(\n",
    "    champion_pools, enemy_champion_pools=None, batch_size=1000\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate team compositions in batches using a generator to avoid storing all in memory.\n",
    "\n",
    "    Args:\n",
    "        champion_pools: Dictionary of champion pools for each role for ally team\n",
    "        enemy_champion_pools: Dictionary of champion pools for each role for enemy team,\n",
    "                             or None to use all UNKNOWNs\n",
    "        batch_size: Number of compositions to yield at once\n",
    "\n",
    "    Yields:\n",
    "        Batches of team compositions\n",
    "    \"\"\"\n",
    "    roles = [\"TOP\", \"JUNGLE\", \"MID\", \"BOT\", \"SUPPORT\"]\n",
    "\n",
    "    # Create iterators for all possible combinations\n",
    "    ally_iter = itertools.product(*[champion_pools[role] for role in roles])\n",
    "\n",
    "    # If no enemy champion pools provided, use all UNKNOWNs\n",
    "    if enemy_champion_pools is None:\n",
    "        enemy_comp = [\"UNKNOWN\"] * 5\n",
    "\n",
    "        # Process ally compositions in batches\n",
    "        batch = []\n",
    "        for ally_comp in ally_iter:\n",
    "            # Check for duplicate champions in ally comp\n",
    "            ally_champion_ids = {\n",
    "                champion.id for champion in ally_comp if champion != \"UNKNOWN\"\n",
    "            }\n",
    "            if len(ally_champion_ids) == sum(\n",
    "                1 for champion in ally_comp if champion != \"UNKNOWN\"\n",
    "            ):\n",
    "                batch.append((ally_comp, enemy_comp))\n",
    "\n",
    "                if len(batch) >= batch_size:\n",
    "                    yield batch\n",
    "                    batch = []\n",
    "\n",
    "        # Yield any remaining compositions\n",
    "        if batch:\n",
    "            yield batch\n",
    "    else:\n",
    "        # Create iterator for enemy compositions\n",
    "        enemy_iter = itertools.product(*[enemy_champion_pools[role] for role in roles])\n",
    "        enemy_comps = []\n",
    "\n",
    "        # Filter valid enemy compositions first (this is smaller than the cartesian product)\n",
    "        for comp in enemy_iter:\n",
    "            champion_ids = {champion.id for champion in comp if champion != \"UNKNOWN\"}\n",
    "            if len(champion_ids) == sum(\n",
    "                1 for champion in comp if champion != \"UNKNOWN\"\n",
    "            ):\n",
    "                enemy_comps.append(\n",
    "                    (comp, {champion.id for champion in comp if champion != \"UNKNOWN\"})\n",
    "                )\n",
    "\n",
    "        # Process ally compositions in batches\n",
    "        batch = []\n",
    "        for ally_comp in ally_iter:\n",
    "            # Check for duplicate champions in ally comp\n",
    "            ally_champion_ids = {\n",
    "                champion.id for champion in ally_comp if champion != \"UNKNOWN\"\n",
    "            }\n",
    "            if len(ally_champion_ids) == sum(\n",
    "                1 for champion in ally_comp if champion != \"UNKNOWN\"\n",
    "            ):\n",
    "\n",
    "                # Check against each valid enemy comp\n",
    "                for enemy_comp, enemy_champion_ids in enemy_comps:\n",
    "                    # Check if there's no overlap between ally and enemy champions\n",
    "                    if not ally_champion_ids.intersection(enemy_champion_ids):\n",
    "                        batch.append((ally_comp, enemy_comp))\n",
    "\n",
    "                        if len(batch) >= batch_size:\n",
    "                            yield batch\n",
    "                            batch = []\n",
    "\n",
    "        # Yield any remaining compositions\n",
    "        if batch:\n",
    "            yield batch\n",
    "\n",
    "\n",
    "def estimate_max_compositions(champion_pools, enemy_champion_pools):\n",
    "    \"\"\"\n",
    "    Calculate the maximum possible number of team compositions (worst case scenario).\n",
    "    This provides an upper bound for the progress bar.\n",
    "\n",
    "    Args:\n",
    "        champion_pools: Dictionary of champion pools for each role for ally team\n",
    "        enemy_champion_pools: Dictionary of champion pools for each role for enemy team\n",
    "\n",
    "    Returns:\n",
    "        Maximum possible number of valid compositions\n",
    "    \"\"\"\n",
    "    roles = [\"TOP\", \"JUNGLE\", \"MID\", \"BOT\", \"SUPPORT\"]\n",
    "\n",
    "    # Count total possible ally compositions\n",
    "    total_ally_comps = 1\n",
    "    for role in roles:\n",
    "        total_ally_comps *= len(champion_pools[role])\n",
    "\n",
    "    # If no enemy champion pools, just return ally count\n",
    "    if enemy_champion_pools is None:\n",
    "        return total_ally_comps\n",
    "\n",
    "    # Count total possible enemy compositions\n",
    "    total_enemy_comps = 1\n",
    "    for role in roles:\n",
    "        total_enemy_comps *= len(enemy_champion_pools[role])\n",
    "\n",
    "    # Maximum possible combinations (worst case - no overlaps)\n",
    "    max_combinations = total_ally_comps * total_enemy_comps\n",
    "\n",
    "    return max_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_process_to_sqlite_parallel(\n",
    "    db_path=\"lol_team_compositions.db\", num_workers=20, commit_frequency=50\n",
    "):\n",
    "    \"\"\"\n",
    "    Process team compositions in parallel batches and write directly to SQLite\n",
    "    with optimized database operations.\n",
    "\n",
    "    Args:\n",
    "        db_path: Path where the SQLite database will be saved\n",
    "        num_workers: Number of parallel workers to use for API calls\n",
    "        commit_frequency: How many batches to process before committing to the database\n",
    "\n",
    "    Returns:\n",
    "        Path to the created database\n",
    "    \"\"\"\n",
    "    import sqlite3\n",
    "    import os\n",
    "    from tqdm.notebook import tqdm\n",
    "    import time\n",
    "    import concurrent.futures\n",
    "    import queue\n",
    "    import threading\n",
    "\n",
    "    # Calculate maximum possible compositions\n",
    "    max_compositions = estimate_max_compositions(champion_pools, enemy_champion_pools)\n",
    "    print(f\"Maximum possible team compositions: {max_compositions:,}\")\n",
    "    print(\"Note: Actual number will be lower due to filtering duplicates and overlaps\")\n",
    "    print(f\"Using {num_workers} parallel workers for API processing\")\n",
    "\n",
    "    # Calculate batch parameters\n",
    "    BATCH_SIZE = 1000  # Compositions per batch\n",
    "\n",
    "    # Estimate number of batches (this is what we'll track in the progress bar)\n",
    "    estimated_batches = (max_compositions + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    print(f\"Estimated number of batches: {estimated_batches:,}\")\n",
    "\n",
    "    # Start timing for rate calculation\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Remove existing database if it exists\n",
    "    if os.path.exists(db_path):\n",
    "        os.remove(db_path)\n",
    "\n",
    "    # Initialize database with optimized settings\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # Apply SQLite optimizations\n",
    "    conn.execute(\n",
    "        \"PRAGMA synchronous = OFF\"\n",
    "    )  # Don't wait for writes to be committed to disk\n",
    "    conn.execute(\"PRAGMA journal_mode = MEMORY\")  # Keep journal in memory\n",
    "    conn.execute(\"PRAGMA temp_store = MEMORY\")  # Store temp tables in memory\n",
    "    conn.execute(\"PRAGMA cache_size = 10000\")  # Increase cache size\n",
    "\n",
    "    # Create champion lookup table\n",
    "    conn.execute(\n",
    "        \"\"\"\n",
    "    CREATE TABLE champion_lookup (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        name TEXT NOT NULL\n",
    "    )\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    # Insert UNKNOWN champion\n",
    "    conn.execute(\"INSERT INTO champion_lookup (id, name) VALUES (0, 'UNKNOWN')\")\n",
    "\n",
    "    # Insert all other champions from our lookup dictionary\n",
    "    for champ_id, champ_name in id_to_name.items():\n",
    "        conn.execute(\n",
    "            \"INSERT INTO champion_lookup (id, name) VALUES (?, ?)\",\n",
    "            (int(champ_id), champ_name),\n",
    "        )\n",
    "\n",
    "    # Create team_comps table\n",
    "    conn.execute(\n",
    "        \"\"\"\n",
    "    CREATE TABLE team_comps (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        ally_top_id INTEGER NOT NULL,\n",
    "        ally_jungle_id INTEGER NOT NULL,\n",
    "        ally_mid_id INTEGER NOT NULL,\n",
    "        ally_bot_id INTEGER NOT NULL,\n",
    "        ally_support_id INTEGER NOT NULL,\n",
    "        enemy_top_id INTEGER NOT NULL,\n",
    "        enemy_jungle_id INTEGER NOT NULL,\n",
    "        enemy_mid_id INTEGER NOT NULL,\n",
    "        enemy_bot_id INTEGER NOT NULL,\n",
    "        enemy_support_id INTEGER NOT NULL,\n",
    "        blue_winrate REAL NOT NULL,\n",
    "        red_winrate REAL NOT NULL,\n",
    "        avg_winrate REAL NOT NULL\n",
    "    )\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    # Create role_champions table for filtering\n",
    "    conn.execute(\n",
    "        \"\"\"\n",
    "    CREATE TABLE role_champions (\n",
    "        role TEXT NOT NULL,\n",
    "        champion_id INTEGER NOT NULL,\n",
    "        PRIMARY KEY (role, champion_id)\n",
    "    )\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    # Insert role champions\n",
    "    roles = [\n",
    "        (\"ally_top\", champion_pools[\"TOP\"]),\n",
    "        (\"ally_jungle\", champion_pools[\"JUNGLE\"]),\n",
    "        (\"ally_mid\", champion_pools[\"MID\"]),\n",
    "        (\"ally_bot\", champion_pools[\"BOT\"]),\n",
    "        (\"ally_support\", champion_pools[\"SUPPORT\"]),\n",
    "        (\"enemy_top\", enemy_champion_pools[\"TOP\"]),\n",
    "        (\"enemy_jungle\", enemy_champion_pools[\"JUNGLE\"]),\n",
    "        (\"enemy_mid\", enemy_champion_pools[\"MID\"]),\n",
    "        (\"enemy_bot\", enemy_champion_pools[\"BOT\"]),\n",
    "        (\"enemy_support\", enemy_champion_pools[\"SUPPORT\"]),\n",
    "    ]\n",
    "\n",
    "    for role_name, champions in roles:\n",
    "        for champion in champions:\n",
    "            champ_id = (\n",
    "                0\n",
    "                if champion == \"UNKNOWN\"\n",
    "                else (champion.id if isinstance(champion, Champion) else champion)\n",
    "            )\n",
    "            if champ_id != \"UNKNOWN\":\n",
    "                champ_id = int(champ_id)\n",
    "            else:\n",
    "                champ_id = 0\n",
    "\n",
    "            conn.execute(\n",
    "                \"INSERT INTO role_champions (role, champion_id) VALUES (?, ?)\",\n",
    "                (role_name, champ_id),\n",
    "            )\n",
    "\n",
    "    # Commit initial schema\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    # Create queues for producer-consumer pattern\n",
    "    comp_batch_queue = queue.Queue(\n",
    "        maxsize=num_workers * 2\n",
    "    )  # Batches for API processing\n",
    "    db_batch_queue = queue.Queue(maxsize=num_workers * 2)  # Results for DB insertion\n",
    "\n",
    "    # Function to process a batch through the API\n",
    "    def process_batch_api(batch):\n",
    "        # Create API requests for this batch - separated for blue and red side\n",
    "        blue_requests = []\n",
    "        red_requests = []\n",
    "\n",
    "        for idx, (ally_comp, enemy_comp) in enumerate(batch):\n",
    "            # Convert champions to IDs, handling UNKNOWN\n",
    "            ally_ids = [\n",
    "                \"UNKNOWN\" if champion == \"UNKNOWN\" else champion.id\n",
    "                for champion in ally_comp\n",
    "            ]\n",
    "            enemy_ids = [\n",
    "                \"UNKNOWN\" if champion == \"UNKNOWN\" else champion.id\n",
    "                for champion in enemy_comp\n",
    "            ]\n",
    "\n",
    "            # Request for blue side (ally team is on blue side)\n",
    "            blue_requests.append(\n",
    "                {\n",
    "                    \"champion_ids\": ally_ids + enemy_ids,\n",
    "                    \"numerical_elo\": numerical_elo,\n",
    "                    \"patch\": patch,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Request for red side (ally team is on red side)\n",
    "            red_requests.append(\n",
    "                {\n",
    "                    \"champion_ids\": enemy_ids + ally_ids,\n",
    "                    \"numerical_elo\": numerical_elo,\n",
    "                    \"patch\": patch,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Make two large API calls instead of many small ones\n",
    "        blue_results = {}\n",
    "        red_results = {}\n",
    "\n",
    "        try:\n",
    "            # Blue side API call - send all blue requests in one batch\n",
    "            blue_response = requests.post(\n",
    "                \"http://0.0.0.0:8000/predict-batch\",\n",
    "                json=blue_requests,\n",
    "                headers=HEADERS,\n",
    "            )\n",
    "            blue_response.raise_for_status()\n",
    "\n",
    "            # Process blue side results\n",
    "            for i, prediction in enumerate(blue_response.json()):\n",
    "                blue_results[i] = prediction[\"win_probability\"]\n",
    "\n",
    "            # Red side API call - send all red requests in one batch\n",
    "            red_response = requests.post(\n",
    "                \"http://0.0.0.0:8000/predict-batch\",\n",
    "                json=red_requests,\n",
    "                headers=HEADERS,\n",
    "            )\n",
    "            red_response.raise_for_status()\n",
    "\n",
    "            # Process red side results (invert probability since we want red side win probability)\n",
    "            for i, prediction in enumerate(red_response.json()):\n",
    "                red_results[i] = 1 - prediction[\"win_probability\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch processing: {e}\")\n",
    "\n",
    "        # Prepare results for database insertion\n",
    "        rows_to_insert = []\n",
    "        for idx, (ally_comp, enemy_comp) in enumerate(batch):\n",
    "            if idx in blue_results and idx in red_results:\n",
    "                # Convert ally champion IDs\n",
    "                ally_top_id = 0 if ally_comp[0] == \"UNKNOWN\" else int(ally_comp[0].id)\n",
    "                ally_jungle_id = (\n",
    "                    0 if ally_comp[1] == \"UNKNOWN\" else int(ally_comp[1].id)\n",
    "                )\n",
    "                ally_mid_id = 0 if ally_comp[2] == \"UNKNOWN\" else int(ally_comp[2].id)\n",
    "                ally_bot_id = 0 if ally_comp[3] == \"UNKNOWN\" else int(ally_comp[3].id)\n",
    "                ally_support_id = (\n",
    "                    0 if ally_comp[4] == \"UNKNOWN\" else int(ally_comp[4].id)\n",
    "                )\n",
    "\n",
    "                # Convert enemy champion IDs\n",
    "                enemy_top_id = (\n",
    "                    0 if enemy_comp[0] == \"UNKNOWN\" else int(enemy_comp[0].id)\n",
    "                )\n",
    "                enemy_jungle_id = (\n",
    "                    0 if enemy_comp[1] == \"UNKNOWN\" else int(enemy_comp[1].id)\n",
    "                )\n",
    "                enemy_mid_id = (\n",
    "                    0 if enemy_comp[2] == \"UNKNOWN\" else int(enemy_comp[2].id)\n",
    "                )\n",
    "                enemy_bot_id = (\n",
    "                    0 if enemy_comp[3] == \"UNKNOWN\" else int(enemy_comp[3].id)\n",
    "                )\n",
    "                enemy_support_id = (\n",
    "                    0 if enemy_comp[4] == \"UNKNOWN\" else int(enemy_comp[4].id)\n",
    "                )\n",
    "\n",
    "                blue_winrate = blue_results[idx]\n",
    "                red_winrate = red_results[idx]\n",
    "                avg_winrate = (blue_winrate + red_winrate) / 2\n",
    "\n",
    "                rows_to_insert.append(\n",
    "                    (\n",
    "                        ally_top_id,\n",
    "                        ally_jungle_id,\n",
    "                        ally_mid_id,\n",
    "                        ally_bot_id,\n",
    "                        ally_support_id,\n",
    "                        enemy_top_id,\n",
    "                        enemy_jungle_id,\n",
    "                        enemy_mid_id,\n",
    "                        enemy_bot_id,\n",
    "                        enemy_support_id,\n",
    "                        blue_winrate,\n",
    "                        red_winrate,\n",
    "                        avg_winrate,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # Return stats and rows to insert\n",
    "        return {\n",
    "            \"compositions_processed\": len(batch),\n",
    "            \"compositions_inserted\": len(rows_to_insert),\n",
    "            \"api_requests\": 2,  # Just two API calls (blue and red)\n",
    "            \"rows\": rows_to_insert,\n",
    "        }\n",
    "\n",
    "    # API worker function - consumes batches and produces database insertions\n",
    "    def api_worker():\n",
    "        while True:\n",
    "            batch = comp_batch_queue.get()\n",
    "            if batch is None:  # Termination signal\n",
    "                comp_batch_queue.task_done()\n",
    "                break\n",
    "\n",
    "            result = process_batch_api(batch)\n",
    "            db_batch_queue.put(result)\n",
    "            comp_batch_queue.task_done()\n",
    "\n",
    "    # Database worker function - consumes results and inserts into database\n",
    "    def db_worker():\n",
    "        # Create a dedicated database connection for this thread\n",
    "        conn = sqlite3.connect(db_path)\n",
    "\n",
    "        # Apply SQLite optimizations\n",
    "        conn.execute(\"PRAGMA synchronous = OFF\")\n",
    "        conn.execute(\"PRAGMA journal_mode = MEMORY\")\n",
    "        conn.execute(\"PRAGMA temp_store = MEMORY\")\n",
    "        conn.execute(\"PRAGMA cache_size = 10000\")\n",
    "\n",
    "        # Track how many batches we've processed before committing\n",
    "        batches_since_commit = 0\n",
    "        total_rows_inserted = 0\n",
    "\n",
    "        while True:\n",
    "            result = db_batch_queue.get()\n",
    "            if result is None:  # Termination signal\n",
    "                db_batch_queue.task_done()\n",
    "                break\n",
    "\n",
    "            # Insert this batch's rows\n",
    "            if result[\"rows\"]:\n",
    "                try:\n",
    "                    conn.executemany(\n",
    "                        \"\"\"\n",
    "                    INSERT INTO team_comps (\n",
    "                        ally_top_id, ally_jungle_id, ally_mid_id, ally_bot_id, ally_support_id,\n",
    "                        enemy_top_id, enemy_jungle_id, enemy_mid_id, enemy_bot_id, enemy_support_id,\n",
    "                        blue_winrate, red_winrate, avg_winrate\n",
    "                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                    \"\"\",\n",
    "                        result[\"rows\"],\n",
    "                    )\n",
    "\n",
    "                    total_rows_inserted += len(result[\"rows\"])\n",
    "                    batches_since_commit += 1\n",
    "\n",
    "                    # Only commit periodically to improve performance\n",
    "                    if batches_since_commit >= commit_frequency:\n",
    "                        conn.commit()\n",
    "                        batches_since_commit = 0\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error inserting into database: {e}\")\n",
    "\n",
    "            # Record results for progress tracking\n",
    "            result_queue.put(result)\n",
    "            db_batch_queue.task_done()\n",
    "\n",
    "        # Final commit before closing\n",
    "        if batches_since_commit > 0:\n",
    "            conn.commit()\n",
    "\n",
    "        conn.close()\n",
    "        print(f\"Database worker completed, inserted {total_rows_inserted:,} rows total\")\n",
    "\n",
    "    # Create a thread-safe queue for progress reporting\n",
    "    result_queue = queue.Queue()\n",
    "\n",
    "    # Create a lock for updating the progress bar\n",
    "    progress_lock = threading.Lock()\n",
    "\n",
    "    # Create shared counters for tracking\n",
    "    total_batches_processed = 0\n",
    "    total_compositions_processed = 0\n",
    "    total_compositions_inserted = 0\n",
    "    total_api_requests = 0\n",
    "\n",
    "    # Create progress bar for batches\n",
    "    pbar = tqdm(total=estimated_batches, desc=\"Processing batches\", miniters=1)\n",
    "\n",
    "    # Function to update progress bar from result queue\n",
    "    def update_progress():\n",
    "        nonlocal total_batches_processed, total_compositions_processed\n",
    "        nonlocal total_compositions_inserted, total_api_requests\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                # Get result from queue with timeout\n",
    "                result = result_queue.get(timeout=1)\n",
    "\n",
    "                # Update counters\n",
    "                with progress_lock:\n",
    "                    total_batches_processed += 1\n",
    "                    total_compositions_processed += result[\"compositions_processed\"]\n",
    "                    total_compositions_inserted += result[\"compositions_inserted\"]\n",
    "                    total_api_requests += result[\"api_requests\"]\n",
    "\n",
    "                    # Calculate rates\n",
    "                    elapsed = time.time() - start_time\n",
    "                    if elapsed > 0:\n",
    "                        batch_rate = total_batches_processed / elapsed\n",
    "                        comp_rate = total_compositions_processed / elapsed\n",
    "\n",
    "                        # Update progress bar description\n",
    "                        pbar.set_description(\n",
    "                            f\"Processed {total_batches_processed:,} batches \"\n",
    "                            f\"({batch_rate:.1f} batches/s, {comp_rate:.1f} comps/s, \"\n",
    "                            f\"{total_compositions_inserted:,} inserted)\"\n",
    "                        )\n",
    "\n",
    "                    # Update progress bar\n",
    "                    pbar.update(1)\n",
    "\n",
    "                # Mark task as done\n",
    "                result_queue.task_done()\n",
    "\n",
    "            except queue.Empty:\n",
    "                # Check if processing is complete\n",
    "                if processing_complete.is_set():\n",
    "                    break\n",
    "\n",
    "    # Flag to signal when processing is complete\n",
    "    processing_complete = threading.Event()\n",
    "\n",
    "    # Start progress updater thread\n",
    "    progress_thread = threading.Thread(target=update_progress)\n",
    "    progress_thread.daemon = True\n",
    "    progress_thread.start()\n",
    "\n",
    "    # Start database worker thread\n",
    "    db_thread = threading.Thread(target=db_worker)\n",
    "    db_thread.daemon = True\n",
    "    db_thread.start()\n",
    "\n",
    "    # Start API worker threads\n",
    "    api_threads = []\n",
    "    for _ in range(num_workers):\n",
    "        thread = threading.Thread(target=api_worker)\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "        api_threads.append(thread)\n",
    "\n",
    "    # Process batches\n",
    "    try:\n",
    "        # Get batch generator\n",
    "        batch_generator = generate_team_comps_stream(\n",
    "            champion_pools, enemy_champion_pools, batch_size=BATCH_SIZE\n",
    "        )\n",
    "\n",
    "        # Feed batches to API workers\n",
    "        for batch in batch_generator:\n",
    "            comp_batch_queue.put(batch)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating batches: {e}\")\n",
    "    finally:\n",
    "        # Signal workers to terminate\n",
    "        for _ in range(num_workers):\n",
    "            comp_batch_queue.put(None)\n",
    "\n",
    "        # Wait for API workers to finish\n",
    "        for thread in api_threads:\n",
    "            thread.join()\n",
    "\n",
    "        # Signal DB worker to terminate\n",
    "        db_batch_queue.put(None)\n",
    "\n",
    "        # Wait for DB worker to finish\n",
    "        db_thread.join()\n",
    "\n",
    "        # Signal that processing is complete\n",
    "        processing_complete.set()\n",
    "\n",
    "        # Wait for progress thread to finish\n",
    "        progress_thread.join()\n",
    "\n",
    "        # Close progress bar\n",
    "        pbar.close()\n",
    "\n",
    "    # Wait for all results to be processed\n",
    "    result_queue.join()\n",
    "\n",
    "    # Create indices for faster querying\n",
    "    print(\"Creating indices for faster querying...\")\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    # Indexes for winrates\n",
    "    conn.execute(\"CREATE INDEX idx_avg_winrate ON team_comps(avg_winrate)\")\n",
    "    conn.execute(\"CREATE INDEX idx_blue_winrate ON team_comps(blue_winrate)\")\n",
    "    conn.execute(\"CREATE INDEX idx_red_winrate ON team_comps(red_winrate)\")\n",
    "\n",
    "    # Indexes for ally champion IDs\n",
    "    conn.execute(\"CREATE INDEX idx_ally_top ON team_comps(ally_top_id)\")\n",
    "    conn.execute(\"CREATE INDEX idx_ally_jungle ON team_comps(ally_jungle_id)\")\n",
    "    conn.execute(\"CREATE INDEX idx_ally_mid ON team_comps(ally_mid_id)\")\n",
    "    conn.execute(\"CREATE INDEX idx_ally_bot ON team_comps(ally_bot_id)\")\n",
    "    conn.execute(\"CREATE INDEX idx_ally_support ON team_comps(ally_support_id)\")\n",
    "\n",
    "    # Indexes for enemy champion IDs\n",
    "    conn.execute(\"CREATE INDEX idx_enemy_top ON team_comps(enemy_top_id)\")\n",
    "    conn.execute(\"CREATE INDEX idx_enemy_jungle ON team_comps(enemy_jungle_id)\")\n",
    "    conn.execute(\"CREATE INDEX idx_enemy_mid ON team_comps(enemy_mid_id)\")\n",
    "    conn.execute(\"CREATE INDEX idx_enemy_bot ON team_comps(enemy_bot_id)\")\n",
    "    conn.execute(\"CREATE INDEX idx_enemy_support ON team_comps(enemy_support_id)\")\n",
    "    conn.commit()\n",
    "\n",
    "    # Get the actual count of inserted compositions\n",
    "    cursor = conn.execute(\"SELECT COUNT(*) FROM team_comps\")\n",
    "    inserted_count = cursor.fetchone()[0]\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"SQLite database created at: {db_path}\")\n",
    "    print(\n",
    "        f\"- Created champion_lookup table with {len(id_to_name) + 1} entries (including UNKNOWN)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"- Processed {total_batches_processed} batches ({total_compositions_processed:,} compositions)\"\n",
    "    )\n",
    "    print(f\"- Made {total_api_requests:,} API requests\")\n",
    "    print(f\"- Inserted {inserted_count:,} team compositions into database\")\n",
    "    print(f\"- All champion IDs are stored as integers (with UNKNOWN as 0)\")\n",
    "\n",
    "    return db_path\n",
    "\n",
    "\n",
    "def estimate_max_compositions(champion_pools, enemy_champion_pools):\n",
    "    \"\"\"\n",
    "    Calculate the maximum possible number of API requests (worst case scenario).\n",
    "    This provides an upper bound for the progress bar.\n",
    "\n",
    "    Args:\n",
    "        champion_pools: Dictionary of champion pools for each role for ally team\n",
    "        enemy_champion_pools: Dictionary of champion pools for each role for enemy team\n",
    "\n",
    "    Returns:\n",
    "        Maximum possible number of API requests (2 per composition)\n",
    "    \"\"\"\n",
    "    roles = [\"TOP\", \"JUNGLE\", \"MID\", \"BOT\", \"SUPPORT\"]\n",
    "\n",
    "    # Count total possible ally compositions\n",
    "    total_ally_comps = 1\n",
    "    for role in roles:\n",
    "        total_ally_comps *= len(champion_pools[role])\n",
    "\n",
    "    # If no enemy champion pools, just return ally count\n",
    "    if enemy_champion_pools is None:\n",
    "        # Multiply by 2 because we make 2 API requests per composition (blue and red side)\n",
    "        return total_ally_comps * 2\n",
    "\n",
    "    # Count total possible enemy compositions\n",
    "    total_enemy_comps = 1\n",
    "    for role in roles:\n",
    "        total_enemy_comps *= len(enemy_champion_pools[role])\n",
    "\n",
    "    # Maximum possible combinations (worst case - no overlaps)\n",
    "    # Multiply by 2 because we make 2 API requests per composition (blue and red side)\n",
    "    max_api_requests = total_ally_comps * total_enemy_comps * 2\n",
    "\n",
    "    return max_api_requests\n",
    "\n",
    "\n",
    "db_path = stream_process_to_sqlite_parallel(num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indices for faster querying\n",
    "import sqlite3\n",
    "\n",
    "print(\"Creating indices for faster querying...\")\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# New indexes for other winrates\n",
    "conn.execute(\"CREATE INDEX idx_blue_winrate ON team_comps(blue_winrate)\")\n",
    "conn.execute(\"CREATE INDEX idx_red_winrate ON team_comps(red_winrate)\")\n",
    "\n",
    "# Indexes for ally champion IDs\n",
    "conn.execute(\"CREATE INDEX idx_ally_top ON team_comps(ally_top_id)\")\n",
    "conn.execute(\"CREATE INDEX idx_ally_jungle ON team_comps(ally_jungle_id)\")\n",
    "conn.execute(\"CREATE INDEX idx_ally_mid ON team_comps(ally_mid_id)\")\n",
    "conn.execute(\"CREATE INDEX idx_ally_bot ON team_comps(ally_bot_id)\")\n",
    "conn.execute(\"CREATE INDEX idx_ally_support ON team_comps(ally_support_id)\")\n",
    "\n",
    "# Indexes for enemy champion IDs\n",
    "conn.execute(\"CREATE INDEX idx_enemy_top ON team_comps(enemy_top_id)\")\n",
    "conn.execute(\"CREATE INDEX idx_enemy_jungle ON team_comps(enemy_jungle_id)\")\n",
    "conn.execute(\"CREATE INDEX idx_enemy_mid ON team_comps(enemy_mid_id)\")\n",
    "conn.execute(\"CREATE INDEX idx_enemy_bot ON team_comps(enemy_bot_id)\")\n",
    "conn.execute(\"CREATE INDEX idx_enemy_support ON team_comps(enemy_support_id)\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
